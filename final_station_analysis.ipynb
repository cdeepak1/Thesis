{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6930e5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data saved to C:\\Deepak\\stations\\MM\\Final\\Bra\\BE-Bra_Fluxnet_Combined.csv\n",
      "Time coverage: 199601 to 202412\n",
      "Variable availability saved to C:\\Deepak\\stations\\MM\\Final\\Bra\\BE-Bra_variable_year_availability.csv\n",
      "Recursive year availability progression saved to C:\\Deepak\\stations\\MM\\Final\\Bra\\BE-Bra_recursive_year_availability.csv\n",
      "Combined data saved to C:\\Deepak\\stations\\MM\\Final\\Hyy\\FI-Hyy_Fluxnet_Combined.csv\n",
      "Time coverage: 199601 to 202412\n",
      "Variable availability saved to C:\\Deepak\\stations\\MM\\Final\\Hyy\\FI-Hyy_variable_year_availability.csv\n",
      "Recursive year availability progression saved to C:\\Deepak\\stations\\MM\\Final\\Hyy\\FI-Hyy_recursive_year_availability.csv\n",
      "Combined data saved to C:\\Deepak\\stations\\MM\\Final\\Tha\\DE-Tha_Fluxnet_Combined.csv\n",
      "Time coverage: 199601 to 202412\n",
      "Variable availability saved to C:\\Deepak\\stations\\MM\\Final\\Tha\\DE-Tha_variable_year_availability.csv\n",
      "Recursive year availability progression saved to C:\\Deepak\\stations\\MM\\Final\\Tha\\DE-Tha_recursive_year_availability.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymannkendall as mk\n",
    "import os\n",
    "from collections import defaultdict, OrderedDict\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "# ======================\n",
    "# DATA PROCESSING MODULE\n",
    "# ======================\n",
    "\n",
    "def combine_fluxnet_datasets(ds1_path: str, ds2_path: str, output_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Combine two FLUXNET datasets, prioritizing non-missing values (-9999) from ds2\n",
    "    \n",
    "    Args:\n",
    "        ds1_path: Path to first dataset (typically older data)\n",
    "        ds2_path: Path to second dataset (typically newer data)\n",
    "        output_path: Path to save combined dataset\n",
    "    \"\"\"\n",
    "    # Core variables to include (TIMESTAMP must be first)\n",
    "    core_vars = [\n",
    "        'TIMESTAMP',\n",
    "        # Base variables\n",
    "        'LE_F_MDS', 'H_F_MDS', 'G_F_MDS', 'NETRAD', 'TA_F',\n",
    "        'TS_F_MDS_1', 'VPD_F', 'P_F', 'SWC_F_MDS_1', 'GPP_NT_VUT_MEAN',\n",
    "        # Corrected versions\n",
    "        'LE_CORR', 'H_CORR',\n",
    "        # Quality control flags\n",
    "        'LE_F_MDS_QC', 'H_F_MDS_QC', 'G_F_MDS_QC', 'TA_F_QC',\n",
    "        'TS_F_MDS_1_QC', 'VPD_F_QC', 'P_F_QC', 'SWC_F_MDS_1_QC',\n",
    "    ]\n",
    "\n",
    "    # Load datasets with only needed columns\n",
    "    ds1 = pd.read_csv(ds1_path, usecols=lambda x: x in core_vars)\n",
    "    ds2 = pd.read_csv(ds2_path, usecols=lambda x: x in core_vars)\n",
    "\n",
    "    # Convert TIMESTAMP to datetime\n",
    "    for df in [ds1, ds2]:\n",
    "        df['TIMESTAMP'] = pd.to_datetime(df['TIMESTAMP'], format='%Y%m')\n",
    "\n",
    "    # Process overlapping dates - prioritize non -9999 values from ds2\n",
    "    overlap_dates = set(ds1['TIMESTAMP']).intersection(set(ds2['TIMESTAMP']))\n",
    "    \n",
    "    for date in overlap_dates:\n",
    "        for var in core_vars[1:]:  # Skip TIMESTAMP\n",
    "            if var in ds1.columns and var in ds2.columns:\n",
    "                val1 = ds1.loc[ds1['TIMESTAMP'] == date, var].values[0]\n",
    "                val2 = ds2.loc[ds2['TIMESTAMP'] == date, var].values[0]\n",
    "                \n",
    "                if val2 != -9999:  # Prefer ds2 value if not missing\n",
    "                    ds1.loc[ds1['TIMESTAMP'] == date, var] = val2\n",
    "\n",
    "    # Remove overlapping dates from ds2 and concatenate\n",
    "    ds2 = ds2[~ds2['TIMESTAMP'].isin(overlap_dates)]\n",
    "    combined_df = pd.concat([ds1, ds2]).sort_values('TIMESTAMP')\n",
    "    \n",
    "    # Convert TIMESTAMP back to original format and save\n",
    "    combined_df['TIMESTAMP'] = combined_df['TIMESTAMP'].dt.strftime('%Y%m')\n",
    "    combined_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"Combined data saved to {output_path}\")\n",
    "    print(f\"Time coverage: {combined_df['TIMESTAMP'].min()} to {combined_df['TIMESTAMP'].max()}\")\n",
    "\n",
    "# ======================\n",
    "# COMPLETENESS ANALYSIS\n",
    "# ======================\n",
    "\n",
    "def validate_variable(df: pd.DataFrame, var: str) -> List[int]:\n",
    "    \"\"\"\n",
    "    Identify complete years for a variable based on QC flags\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame with data\n",
    "        var: Variable name to validate\n",
    "    \n",
    "    Returns:\n",
    "        List of years with complete data (12 months)\n",
    "    \"\"\"\n",
    "    qc_col = var + '_QC' if var + '_QC' in df.columns else None\n",
    "    \n",
    "    if qc_col:\n",
    "        valid_mask = (df[qc_col] > 0.8) & (df[var] != -9999.0)\n",
    "    else:\n",
    "        valid_mask = (df[var] != -9999.0)\n",
    "    \n",
    "    valid_data = df[valid_mask].copy()\n",
    "    valid_year_counts = valid_data['Year'].value_counts()\n",
    "    return valid_year_counts[valid_year_counts == 12].index.tolist()\n",
    "\n",
    "def get_complete_years(df: pd.DataFrame, variables: List[str]) -> List[int]:\n",
    "    \"\"\"\n",
    "    Find years where all specified variables have complete data\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame with data\n",
    "        variables: List of variables to check\n",
    "    \n",
    "    Returns:\n",
    "        Sorted list of years with complete data for all variables\n",
    "    \"\"\"\n",
    "    common_years = set(df['Year'].unique())\n",
    "    for var in variables:\n",
    "        valid_years = validate_variable(df, var)\n",
    "        common_years.intersection_update(valid_years)\n",
    "    return sorted(common_years)\n",
    "\n",
    "def identify_problematic_variable(df: pd.DataFrame, variables: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    Find which variable reduces completeness the most\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame with data\n",
    "        variables: List of variables to evaluate\n",
    "    \n",
    "    Returns:\n",
    "        Name of the most problematic variable\n",
    "    \"\"\"\n",
    "    base_years = get_complete_years(df, variables)\n",
    "    var_impact = {}\n",
    "    \n",
    "    for var in variables:\n",
    "        test_vars = [v for v in variables if v != var]\n",
    "        test_years = get_complete_years(df, test_vars)\n",
    "        var_impact[var] = len(test_years) - len(base_years)\n",
    "    \n",
    "    return max(var_impact.items(), key=lambda x: x[1])[0]\n",
    "\n",
    "\n",
    "def save_variable_year_availability(df: pd.DataFrame, variables: List[str], output_file: str) -> None:\n",
    "    \"\"\"\n",
    "    Save availability of each variable (years with valid data after QC and missing check)\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with Year, QC, and variable columns\n",
    "        variables: List of variables to check\n",
    "        output_file: Path to save CSV\n",
    "    \"\"\"\n",
    "    availability_records = []\n",
    "\n",
    "    for var in variables:\n",
    "        valid_years = validate_variable(df, var)\n",
    "        availability_records.append({\n",
    "            \"Variable\": var,\n",
    "            \"Valid_Years\": \", \".join(map(str, sorted(valid_years))),\n",
    "            \"Count_Valid_Years\": len(valid_years)\n",
    "        })\n",
    "\n",
    "    availability_df = pd.DataFrame(availability_records)\n",
    "    availability_df.to_csv(output_file, index=False)\n",
    "    print(f\"Variable availability saved to {output_file}\")\n",
    "\n",
    "\n",
    "def save_recursive_year_availability(df: pd.DataFrame, variables: List[str], output_file: str) -> None:\n",
    "    \"\"\"\n",
    "    Save recursive completeness progression:\n",
    "    Start with all variables, list available years,\n",
    "    then remove the most problematic variable and repeat.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with Year and variables\n",
    "        variables: List of variables to analyze\n",
    "        output_file: Path to save CSV\n",
    "    \"\"\"\n",
    "    progression_records = []\n",
    "    current_vars = variables.copy()\n",
    "\n",
    "    while len(current_vars) > 1:\n",
    "        complete_years = get_complete_years(df, current_vars)\n",
    "        progression_records.append({\n",
    "            \"Step\": len(progression_records) + 1,\n",
    "            \"Variables_Included\": \", \".join(current_vars),\n",
    "            \"Count_Variables\": len(current_vars),\n",
    "            \"Years_Available\": \", \".join(map(str, complete_years)),\n",
    "            \"Count_Years\": len(complete_years)\n",
    "        })\n",
    "\n",
    "        if len(current_vars) > 2:\n",
    "            problematic_var = identify_problematic_variable(df, current_vars)\n",
    "            current_vars.remove(problematic_var)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    progression_df = pd.DataFrame(progression_records)\n",
    "    progression_df.to_csv(output_file, index=False)\n",
    "    print(f\"Recursive year availability progression saved to {output_file}\")\n",
    "\n",
    "\n",
    "# ======================\n",
    "# YEARLY ANALYSIS\n",
    "# ======================\n",
    "\n",
    "def calculate_yearly_means(df: pd.DataFrame, variables: List[str], years: List[int]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate yearly means for complete years only\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame with data\n",
    "        variables: Variables to calculate means for\n",
    "        years: Years to include\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with yearly means\n",
    "    \"\"\"\n",
    "    if not years:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    complete_data = df[df['Year'].isin(years)]\n",
    "    return complete_data.groupby('Year')[variables].mean()\n",
    "\n",
    "def generate_recursive_means(df: pd.DataFrame, variables: List[str]) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Generate yearly means by recursively removing problematic variables\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame with data\n",
    "        variables: List of variables to analyze\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of DataFrames with different variable combinations\n",
    "    \"\"\"\n",
    "    results = OrderedDict()\n",
    "    current_vars = variables.copy()\n",
    "    \n",
    "    # Initial run with all variables\n",
    "    complete_years = get_complete_years(df, current_vars)\n",
    "    yearly_means = calculate_yearly_means(df, current_vars, complete_years)\n",
    "    results[\"All Variables\"] = yearly_means\n",
    "    \n",
    "    # Recursively remove most problematic variable\n",
    "    while len(current_vars) > 2:\n",
    "        problematic_var = identify_problematic_variable(df, current_vars)\n",
    "        current_vars.remove(problematic_var)\n",
    "        \n",
    "        complete_years = get_complete_years(df, current_vars)\n",
    "        yearly_means = calculate_yearly_means(df, current_vars, complete_years)\n",
    "        results[f\"Excluded {problematic_var}\"] = yearly_means\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ======================\n",
    "# SEASONAL ANALYSIS\n",
    "# ======================\n",
    "\n",
    "def get_season_months(season: str) -> List[int]:\n",
    "    \"\"\"Return months for each season (with DJF year adjustment)\"\"\"\n",
    "    return {\n",
    "        'DJF': [12, 1, 2],  # December, January, February\n",
    "        'MAM': [3, 4, 5],   # March, April, May\n",
    "        'JJA': [6, 7, 8],   # June, July, August\n",
    "        'SON': [9, 10, 11]  # September, October, November\n",
    "    }[season]\n",
    "\n",
    "def get_complete_seasons(df: pd.DataFrame, variables: List[str], season: str) -> List[int]:\n",
    "    \"\"\"\n",
    "    Get seasons with complete data for all variables\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame\n",
    "        variables: Variables to check\n",
    "        season: Season code (DJF, MAM, JJA, SON)\n",
    "    \n",
    "    Returns:\n",
    "        List of complete season years\n",
    "    \"\"\"\n",
    "    season_months = get_season_months(season)\n",
    "    df_season = df[df['Month'].isin(season_months)].copy()\n",
    "    \n",
    "    # Adjust year for winter season (DJF)\n",
    "    if season == 'DJF':\n",
    "        df_season['Season_Year'] = df_season['Year']\n",
    "        df_season.loc[df_season['Month'] == 12, 'Season_Year'] += 1\n",
    "    else:\n",
    "        df_season['Season_Year'] = df_season['Year']\n",
    "    \n",
    "    # Find seasons with all months present\n",
    "    month_counts = df_season.groupby(['Season_Year'])['Month'].nunique()\n",
    "    complete_seasons = month_counts[month_counts == 3].index.tolist()\n",
    "    \n",
    "    # Check variable completeness\n",
    "    valid_seasons = []\n",
    "    for season_year in complete_seasons:\n",
    "        season_data = df_season[df_season['Season_Year'] == season_year]\n",
    "        valid = True\n",
    "        for var in variables:\n",
    "            if var+'_QC' in df.columns:\n",
    "                var_data = season_data[(season_data[var+'_QC'] > 0.8) & (season_data[var] != -9999.0)]\n",
    "            else:\n",
    "                var_data = season_data[season_data[var] != -9999.0]\n",
    "            if len(var_data) < 3:  # Not all months valid\n",
    "                valid = False\n",
    "                break\n",
    "        if valid:\n",
    "            valid_seasons.append(season_year)\n",
    "    \n",
    "    return sorted(valid_seasons)\n",
    "\n",
    "def generate_recursive_seasonal_means(df: pd.DataFrame, variables: List[str], season: str) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Generate seasonal means by recursively removing problematic variables\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame\n",
    "        variables: Variables to analyze\n",
    "        season: Season code (DJF, MAM, JJA, SON)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of DataFrames with different variable combinations\n",
    "    \"\"\"\n",
    "    results = OrderedDict()\n",
    "    current_vars = variables.copy()\n",
    "    \n",
    "    # Initial run with all variables\n",
    "    complete_seasons = get_complete_seasons(df, current_vars, season)\n",
    "    seasonal_means = calculate_seasonal_means(df, current_vars, season, complete_seasons)\n",
    "    results[\"All Variables\"] = seasonal_means\n",
    "    \n",
    "    # Recursively remove problematic variables\n",
    "    while len(current_vars) > 2:\n",
    "        problematic_var = identify_problematic_variable_season(df, current_vars, season)\n",
    "        if not problematic_var:\n",
    "            break\n",
    "            \n",
    "        current_vars.remove(problematic_var)\n",
    "        complete_seasons = get_complete_seasons(df, current_vars, season)\n",
    "        seasonal_means = calculate_seasonal_means(df, current_vars, season, complete_seasons)\n",
    "        results[f\"Excluded {problematic_var}\"] = seasonal_means\n",
    "    \n",
    "    return results\n",
    "\n",
    "def calculate_seasonal_means(df: pd.DataFrame, variables: List[str], season: str, season_years: List[int]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate seasonal means for complete seasons\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame\n",
    "        variables: Variables to calculate means for\n",
    "        season: Season code (DJF, MAM, JJA, SON)\n",
    "        season_years: List of years with complete seasonal data\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with seasonal means\n",
    "    \"\"\"\n",
    "    if not season_years:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    season_months = get_season_months(season)\n",
    "    df_season = df[df['Month'].isin(season_months)].copy()\n",
    "    \n",
    "    # Adjust year for winter season (DJF)\n",
    "    if season == 'DJF':\n",
    "        df_season['Season_Year'] = df_season['Year']\n",
    "        df_season.loc[df_season['Month'] == 12, 'Season_Year'] += 1\n",
    "    else:\n",
    "        df_season['Season_Year'] = df_season['Year']\n",
    "    \n",
    "    # Filter for complete seasons\n",
    "    df_season = df_season[df_season['Season_Year'].isin(season_years)]\n",
    "    \n",
    "    # Calculate seasonal means\n",
    "    seasonal_means = df_season.groupby('Season_Year')[variables].mean()\n",
    "    seasonal_means['Season'] = season\n",
    "    return seasonal_means.reset_index().set_index(['Season_Year', 'Season'])\n",
    "\n",
    "def identify_problematic_variable_season(df: pd.DataFrame, variables: List[str], season: str) -> str:\n",
    "    \"\"\"\n",
    "    Find which variable reduces seasonal completeness the most\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame\n",
    "        variables: Variables to evaluate\n",
    "        season: Season code (DJF, MAM, JJA, SON)\n",
    "    \n",
    "    Returns:\n",
    "        Name of the most problematic variable\n",
    "    \"\"\"\n",
    "    base_seasons = get_complete_seasons(df, variables, season)\n",
    "    var_impact = {}\n",
    "    \n",
    "    for var in variables:\n",
    "        test_vars = [v for v in variables if v != var]\n",
    "        test_seasons = get_complete_seasons(df, test_vars, season)\n",
    "        var_impact[var] = len(test_seasons) - len(base_seasons)\n",
    "    \n",
    "    return max(var_impact.items(), key=lambda x: x[1])[0] if var_impact else None\n",
    "\n",
    "# ======================\n",
    "# TREND ANALYSIS\n",
    "# ======================\n",
    "\n",
    "def calculate_trend_stats(series: pd.Series) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculate Mann-Kendall trend statistics\n",
    "    \n",
    "    Args:\n",
    "        series: Time series data\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with slope, p-value, and period info\n",
    "    \"\"\"\n",
    "    if series.notna().sum() < 10:\n",
    "        return None\n",
    "    \n",
    "    start_year = int(series.index.min())\n",
    "    end_year = int(series.index.max())\n",
    "    full_index = np.arange(start_year, end_year + 1, 1)\n",
    "    series = series.reindex(full_index)\n",
    "    \n",
    "    try:\n",
    "        result = mk.original_test(series.values)\n",
    "        return {\n",
    "            'slope': result.slope,\n",
    "            'p_value': result.p,\n",
    "            'period': f\"{start_year}-{end_year} ({series.notna().sum()})\"\n",
    "        }\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def build_trend_tables(sheets: Dict[str, pd.DataFrame]) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Build p-value and slope tables from analysis results\n",
    "    \n",
    "    Args:\n",
    "        sheets: Dictionary of DataFrames from analysis\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (p-value table, slope table)\n",
    "    \"\"\"\n",
    "    year_groups = defaultdict(list)\n",
    "    \n",
    "    # Sort sheets by number of variables (ascending)\n",
    "    sorted_sheets = sorted(sheets.items(),\n",
    "                         key=lambda x: len([col for col in x[1].columns if col not in ['Season_Year', 'Season']]),\n",
    "                         reverse=False)\n",
    "\n",
    "    for sheet_name, data in sorted_sheets:\n",
    "        if 'Season_Year' in data.columns:\n",
    "            data = data.set_index('Season_Year')\n",
    "        elif 'Year' in data.columns:\n",
    "            data = data.set_index('Year')\n",
    "\n",
    "        vars_included = [col for col in data.columns if col not in ['Season', 'Year']]\n",
    "        if len(vars_included) < 2:\n",
    "            continue\n",
    "\n",
    "        # Calculate stats for all variables\n",
    "        stats_dict = {}\n",
    "        period = None\n",
    "        for var in vars_included:\n",
    "            stats = calculate_trend_stats(data[var].dropna())\n",
    "            if stats:\n",
    "                stats_dict[var] = {\n",
    "                    'p_value': stats['p_value'],\n",
    "                    'slope': stats['slope']\n",
    "                }\n",
    "                period = stats['period']\n",
    "        \n",
    "        if stats_dict:\n",
    "            year_groups[period].append({\n",
    "                'vars': vars_included,\n",
    "                'stats': stats_dict\n",
    "            })\n",
    "    \n",
    "    # Build final tables\n",
    "    p_table, slope_table = [], []\n",
    "    \n",
    "    for period, combinations in year_groups.items():\n",
    "        max_vars = max(len(c['vars']) for c in combinations)\n",
    "        best_comb = next(c for c in combinations if len(c['vars']) == max_vars)\n",
    "        \n",
    "        p_row = {'Years': period, 'Variable Combination': ', '.join(best_comb['vars'])}\n",
    "        s_row = {'Years': period, 'Variable Combination': ', '.join(best_comb['vars'])}\n",
    "        \n",
    "        for var in best_comb['vars']:\n",
    "            p_row[var] = best_comb['stats'][var]['p_value']\n",
    "            s_row[var] = best_comb['stats'][var]['slope']\n",
    "        \n",
    "        p_table.append(p_row)\n",
    "        slope_table.append(s_row)\n",
    "    \n",
    "    return pd.DataFrame(p_table), pd.DataFrame(slope_table)\n",
    "\n",
    "# ======================\n",
    "# MAIN EXECUTION\n",
    "# ======================\n",
    "\n",
    "def run_full_analysis(station_code: str = \"FI-Hyy\"):\n",
    "    \"\"\"Run complete analysis pipeline with outputs in station-specific folder\"\"\"\n",
    "\n",
    "    # Build folder path automatically from station code\n",
    "    station_folder_name = station_code.split(\"-\")[1]  # e.g., \"FI-Bra\" -> \"Bra\"\n",
    "    base_dir = os.path.join(r\"C:\\Deepak\\stations\\MM\\Final\", station_folder_name)\n",
    "\n",
    "    # Make sure output folder exists\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "    # File paths for inputs\n",
    "    ds1_path = os.path.join(base_dir, f'FLX_{station_code}_FLUXNET2015_FULLSET_MM_1996-2020_beta-3.csv')\n",
    "    ds2_path = os.path.join(base_dir, f'ICOSETC_{station_code}_FLUXNET_MM_L2.csv')\n",
    "\n",
    "    # File path for combined dataset\n",
    "    combined_path = os.path.join(base_dir, f\"{station_code}_Fluxnet_Combined.csv\")\n",
    "\n",
    "    # Combine datasets\n",
    "    combine_fluxnet_datasets(ds1_path, ds2_path, combined_path)\n",
    "\n",
    "    # Load and prepare data\n",
    "    df = pd.read_csv(combined_path)\n",
    "    df['TIMESTAMP'] = pd.to_datetime(df['TIMESTAMP'], format='%Y%m')\n",
    "    df['Year'] = df['TIMESTAMP'].dt.year\n",
    "    df['Month'] = df['TIMESTAMP'].dt.month\n",
    "\n",
    "    # Get variable columns (excluding QC and metadata)\n",
    "    variables = [col for col in df.columns\n",
    "                 if not col.endswith('_QC')\n",
    "                 and col not in ['TIMESTAMP', 'Year', 'Month']]\n",
    "\n",
    "    # Save variable availability reports\n",
    "    save_variable_year_availability(df, variables, os.path.join(base_dir, f\"{station_code}_variable_year_availability.csv\"))\n",
    "    save_recursive_year_availability(df, variables, os.path.join(base_dir, f\"{station_code}_recursive_year_availability.csv\"))\n",
    "\n",
    "    # Yearly analysis\n",
    "    yearly_results = generate_recursive_means(df, variables)\n",
    "    yearly_file = os.path.join(base_dir, f'strict_recursive_yearly_means_{station_code}.xlsx')\n",
    "    with pd.ExcelWriter(yearly_file) as writer:\n",
    "        for sheet_name, data in yearly_results.items():\n",
    "            if not data.empty:\n",
    "                data.to_excel(writer, sheet_name=sheet_name[:31])\n",
    "\n",
    "    # Seasonal analysis\n",
    "    seasons = ['DJF', 'MAM', 'JJA', 'SON']\n",
    "    for season in seasons:\n",
    "        seasonal_results = generate_recursive_seasonal_means(df, variables, season)\n",
    "        seasonal_file = os.path.join(base_dir, f\"strict_recursive_seasonal_means_{station_code}_{season}.xlsx\")\n",
    "        with pd.ExcelWriter(seasonal_file) as writer:\n",
    "            for sheet_name, data in seasonal_results.items():\n",
    "                if not data.empty:\n",
    "                    data.reset_index().to_excel(writer, sheet_name=sheet_name[:31], index=False)\n",
    "\n",
    "    # Yearly trend analysis\n",
    "    yearly_sheets = pd.read_excel(yearly_file, sheet_name=None)\n",
    "    p_table, slope_table = build_trend_tables(yearly_sheets)\n",
    "    with pd.ExcelWriter(os.path.join(base_dir, f'progressive_trend_tables_{station_code}_yearly.xlsx')) as writer:\n",
    "        p_table.to_excel(writer, sheet_name='P-values', index=False)\n",
    "        slope_table.to_excel(writer, sheet_name='Slopes', index=False)\n",
    "\n",
    "    # Seasonal trend analysis\n",
    "    for season in seasons:\n",
    "        seasonal_file = os.path.join(base_dir, f\"strict_recursive_seasonal_means_{station_code}_{season}.xlsx\")\n",
    "        try:\n",
    "            seasonal_sheets = pd.read_excel(seasonal_file, sheet_name=None)\n",
    "            p_table, slope_table = build_trend_tables(seasonal_sheets)\n",
    "            with pd.ExcelWriter(os.path.join(base_dir, f'progressive_trend_tables_{station_code}_{season}.xlsx')) as writer:\n",
    "                p_table.to_excel(writer, sheet_name='P-values', index=False)\n",
    "                slope_table.to_excel(writer, sheet_name='Slopes', index=False)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: No data file found for {season} season\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_full_analysis(\"BE-Bra\")\n",
    "    run_full_analysis(\"FI-Hyy\")\n",
    "    run_full_analysis(\"DE-Tha\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3f995d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.050477473834512177)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pymannkendall as mk\n",
    "\n",
    "\n",
    "data = np.array([\n",
    "    3.453767083, 3.77697995, 4.0161395, 4.404460742, 4.260551275, 4.174563833,\n",
    "    4.48972, 3.382869083, 3.7710225, 3.832464992, 3.558067917, 2.434592333,\n",
    "    4.369564583, 4.369519667, 3.97802885, 4.14561475, 3.896000667, 3.922338,\n",
    "    4.462562417, 4.30264775, 4.69167225, 4.60689075, 3.749627583, 4.18201275,\n",
    "    2.349085, 4.921183667, 4.48183975, 4.792183417\n",
    "])\n",
    "\n",
    "# Perform Mann-Kendall test\n",
    "result = mk.original_test(data)\n",
    "\n",
    "\n",
    "result.p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c1595e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.050477473834512177)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data2 = np.array([\n",
    "    33.071961, 27.47026983, 24.3015225, 27.10003867, 26.201129, 20.44217867,\n",
    "    21.03798275, 41.29880267, 28.33163833, 29.40995273, 28.45507667, 28.644646,\n",
    "    26.62623083, 27.03697333, 26.99581083, 34.16811217, 31.13212267, 24.44250333,\n",
    "    26.21327083, 32.5066, 27.1318475, 27.85178525, 44.43696167, 34.50343833,\n",
    "    -14.1410875, 34.15065167, 46.66989083, 36.96086583\n",
    "])\n",
    "\n",
    "\n",
    "result1 = mk.original_test(data2)\n",
    "\n",
    "# Extract p-value\n",
    "result1.p\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
