{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65390976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 47 HOLAPS stations: ['AT-Neu', 'BE-Bra', 'BE-Lon', 'BE-Vie', 'CH-Cha', 'CH-Dav', 'CH-Fru', 'CZ-BK1', 'CZ-wet', 'DE-Geb', 'DE-Gri', 'DE-Hai', 'DE-HoH', 'DE-Hzd', 'DE-Kli', 'DE-Lnf', 'DE-Obe', 'DE-RuR', 'DE-RuS', 'DE-Tha', 'DK-Sor', 'ES-Agu', 'ES-LJu', 'FI-Hyy', 'FI-Let', 'FR-Aur', 'FR-Bil', 'FR-Gri', 'FR-Hes', 'FR-Lam', 'FR-LBr', 'IT-BCi', 'IT-Col', 'IT-Cp2', 'IT-Cpz', 'IT-Lav', 'IT-MBo', 'IT-Ren', 'IT-Ro2', 'IT-SR2', 'IT-SRo', 'IT-Tor', 'IT-TrF', 'NL-Loo', 'RU-Fyo', 'SE-Htm', 'SE-Nor']\n",
      "\n",
      "==================================================\n",
      "Processing HOLAPS station: AT-Neu\n",
      "==================================================\n",
      "Loading HOLAPS data for AT-Neu...\n",
      "Data period: 2001 to 2020\n",
      "Total years: 20\n",
      "HOLAPS variable availability saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\AT-Neu\\AT-Neu_holaps_variable_availability.csv\n",
      "Performing yearly analysis...\n",
      "Yearly means saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\AT-Neu\\holaps_yearly_means_AT-Neu.xlsx\n",
      "Performing seasonal analysis...\n",
      "Seasonal means for DJF saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\AT-Neu\\holaps_seasonal_means_AT-Neu_DJF.xlsx\n",
      "Seasonal means for MAM saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\AT-Neu\\holaps_seasonal_means_AT-Neu_MAM.xlsx\n",
      "Seasonal means for JJA saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\AT-Neu\\holaps_seasonal_means_AT-Neu_JJA.xlsx\n",
      "Seasonal means for SON saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\AT-Neu\\holaps_seasonal_means_AT-Neu_SON.xlsx\n",
      "Performing trend analysis...\n",
      "Yearly trend tables saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\AT-Neu\\holaps_trend_tables_AT-Neu_yearly.xlsx\n",
      "Seasonal trend tables for DJF saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\AT-Neu\\holaps_trend_tables_AT-Neu_DJF.xlsx\n",
      "Seasonal trend tables for MAM saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\AT-Neu\\holaps_trend_tables_AT-Neu_MAM.xlsx\n",
      "Seasonal trend tables for JJA saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\AT-Neu\\holaps_trend_tables_AT-Neu_JJA.xlsx\n",
      "Seasonal trend tables for SON saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\AT-Neu\\holaps_trend_tables_AT-Neu_SON.xlsx\n",
      "✓ Completed analysis for AT-Neu\n",
      "\n",
      "==================================================\n",
      "Processing HOLAPS station: BE-Bra\n",
      "==================================================\n",
      "Loading HOLAPS data for BE-Bra...\n",
      "Data period: 2001 to 2020\n",
      "Total years: 20\n",
      "HOLAPS variable availability saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\BE-Bra\\BE-Bra_holaps_variable_availability.csv\n",
      "Performing yearly analysis...\n",
      "Yearly means saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\BE-Bra\\holaps_yearly_means_BE-Bra.xlsx\n",
      "Performing seasonal analysis...\n",
      "Seasonal means for DJF saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\BE-Bra\\holaps_seasonal_means_BE-Bra_DJF.xlsx\n",
      "Seasonal means for MAM saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\BE-Bra\\holaps_seasonal_means_BE-Bra_MAM.xlsx\n",
      "Seasonal means for JJA saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\BE-Bra\\holaps_seasonal_means_BE-Bra_JJA.xlsx\n",
      "Seasonal means for SON saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\BE-Bra\\holaps_seasonal_means_BE-Bra_SON.xlsx\n",
      "Performing trend analysis...\n",
      "Yearly trend tables saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\BE-Bra\\holaps_trend_tables_BE-Bra_yearly.xlsx\n",
      "Seasonal trend tables for DJF saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\BE-Bra\\holaps_trend_tables_BE-Bra_DJF.xlsx\n",
      "Seasonal trend tables for MAM saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\BE-Bra\\holaps_trend_tables_BE-Bra_MAM.xlsx\n",
      "Seasonal trend tables for JJA saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\BE-Bra\\holaps_trend_tables_BE-Bra_JJA.xlsx\n",
      "Seasonal trend tables for SON saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\BE-Bra\\holaps_trend_tables_BE-Bra_SON.xlsx\n",
      "✓ Completed analysis for BE-Bra\n",
      "\n",
      "==================================================\n",
      "Processing HOLAPS station: BE-Lon\n",
      "==================================================\n",
      "Loading HOLAPS data for BE-Lon...\n",
      "Data period: 2001 to 2020\n",
      "Total years: 20\n",
      "HOLAPS variable availability saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\BE-Lon\\BE-Lon_holaps_variable_availability.csv\n",
      "Performing yearly analysis...\n",
      "Yearly means saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\BE-Lon\\holaps_yearly_means_BE-Lon.xlsx\n",
      "Performing seasonal analysis...\n",
      "Seasonal means for DJF saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\BE-Lon\\holaps_seasonal_means_BE-Lon_DJF.xlsx\n",
      "Seasonal means for MAM saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\BE-Lon\\holaps_seasonal_means_BE-Lon_MAM.xlsx\n",
      "Seasonal means for JJA saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\BE-Lon\\holaps_seasonal_means_BE-Lon_JJA.xlsx\n",
      "Seasonal means for SON saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\BE-Lon\\holaps_seasonal_means_BE-Lon_SON.xlsx\n",
      "Performing trend analysis...\n",
      "Yearly trend tables saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\BE-Lon\\holaps_trend_tables_BE-Lon_yearly.xlsx\n",
      "Seasonal trend tables for DJF saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\BE-Lon\\holaps_trend_tables_BE-Lon_DJF.xlsx\n",
      "Seasonal trend tables for MAM saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\BE-Lon\\holaps_trend_tables_BE-Lon_MAM.xlsx\n",
      "Seasonal trend tables for JJA saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\BE-Lon\\holaps_trend_tables_BE-Lon_JJA.xlsx\n",
      "Seasonal trend tables for SON saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\BE-Lon\\holaps_trend_tables_BE-Lon_SON.xlsx\n",
      "✓ Completed analysis for BE-Lon\n",
      "\n",
      "==================================================\n",
      "Processing HOLAPS station: BE-Vie\n",
      "==================================================\n",
      "Loading HOLAPS data for BE-Vie...\n",
      "Data period: 2001 to 2020\n",
      "Total years: 20\n",
      "HOLAPS variable availability saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\BE-Vie\\BE-Vie_holaps_variable_availability.csv\n",
      "Performing yearly analysis...\n",
      "Yearly means saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\BE-Vie\\holaps_yearly_means_BE-Vie.xlsx\n",
      "Performing seasonal analysis...\n",
      "Seasonal means for DJF saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\BE-Vie\\holaps_seasonal_means_BE-Vie_DJF.xlsx\n",
      "Seasonal means for MAM saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\BE-Vie\\holaps_seasonal_means_BE-Vie_MAM.xlsx\n",
      "Seasonal means for JJA saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\BE-Vie\\holaps_seasonal_means_BE-Vie_JJA.xlsx\n",
      "Seasonal means for SON saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\BE-Vie\\holaps_seasonal_means_BE-Vie_SON.xlsx\n",
      "Performing trend analysis...\n",
      "Yearly trend tables saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\BE-Vie\\holaps_trend_tables_BE-Vie_yearly.xlsx\n",
      "Seasonal trend tables for DJF saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\BE-Vie\\holaps_trend_tables_BE-Vie_DJF.xlsx\n",
      "Seasonal trend tables for MAM saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\BE-Vie\\holaps_trend_tables_BE-Vie_MAM.xlsx\n",
      "Seasonal trend tables for JJA saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\BE-Vie\\holaps_trend_tables_BE-Vie_JJA.xlsx\n",
      "Seasonal trend tables for SON saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\BE-Vie\\holaps_trend_tables_BE-Vie_SON.xlsx\n",
      "✓ Completed analysis for BE-Vie\n",
      "\n",
      "==================================================\n",
      "Processing HOLAPS station: CH-Cha\n",
      "==================================================\n",
      "Loading HOLAPS data for CH-Cha...\n",
      "Data period: 2001 to 2020\n",
      "Total years: 20\n",
      "HOLAPS variable availability saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\CH-Cha\\CH-Cha_holaps_variable_availability.csv\n",
      "Performing yearly analysis...\n",
      "Yearly means saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\CH-Cha\\holaps_yearly_means_CH-Cha.xlsx\n",
      "Performing seasonal analysis...\n",
      "Seasonal means for DJF saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\CH-Cha\\holaps_seasonal_means_CH-Cha_DJF.xlsx\n",
      "Seasonal means for MAM saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\CH-Cha\\holaps_seasonal_means_CH-Cha_MAM.xlsx\n",
      "Seasonal means for JJA saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\CH-Cha\\holaps_seasonal_means_CH-Cha_JJA.xlsx\n",
      "Seasonal means for SON saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\CH-Cha\\holaps_seasonal_means_CH-Cha_SON.xlsx\n",
      "Performing trend analysis...\n",
      "Yearly trend tables saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\CH-Cha\\holaps_trend_tables_CH-Cha_yearly.xlsx\n",
      "Seasonal trend tables for DJF saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\CH-Cha\\holaps_trend_tables_CH-Cha_DJF.xlsx\n",
      "Seasonal trend tables for MAM saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\CH-Cha\\holaps_trend_tables_CH-Cha_MAM.xlsx\n",
      "Seasonal trend tables for JJA saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\CH-Cha\\holaps_trend_tables_CH-Cha_JJA.xlsx\n",
      "Seasonal trend tables for SON saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\CH-Cha\\holaps_trend_tables_CH-Cha_SON.xlsx\n",
      "✓ Completed analysis for CH-Cha\n",
      "\n",
      "==================================================\n",
      "Processing HOLAPS station: CH-Dav\n",
      "==================================================\n",
      "Loading HOLAPS data for CH-Dav...\n",
      "Data period: 2001 to 2020\n",
      "Total years: 20\n",
      "HOLAPS variable availability saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\CH-Dav\\CH-Dav_holaps_variable_availability.csv\n",
      "Performing yearly analysis...\n",
      "Yearly means saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\CH-Dav\\holaps_yearly_means_CH-Dav.xlsx\n",
      "Performing seasonal analysis...\n",
      "Seasonal means for DJF saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\CH-Dav\\holaps_seasonal_means_CH-Dav_DJF.xlsx\n",
      "Seasonal means for MAM saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\CH-Dav\\holaps_seasonal_means_CH-Dav_MAM.xlsx\n",
      "Seasonal means for JJA saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\CH-Dav\\holaps_seasonal_means_CH-Dav_JJA.xlsx\n",
      "Seasonal means for SON saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\CH-Dav\\holaps_seasonal_means_CH-Dav_SON.xlsx\n",
      "Performing trend analysis...\n",
      "Yearly trend tables saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\CH-Dav\\holaps_trend_tables_CH-Dav_yearly.xlsx\n",
      "Seasonal trend tables for DJF saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\CH-Dav\\holaps_trend_tables_CH-Dav_DJF.xlsx\n",
      "Seasonal trend tables for MAM saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\CH-Dav\\holaps_trend_tables_CH-Dav_MAM.xlsx\n",
      "Seasonal trend tables for JJA saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\CH-Dav\\holaps_trend_tables_CH-Dav_JJA.xlsx\n",
      "Seasonal trend tables for SON saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\CH-Dav\\holaps_trend_tables_CH-Dav_SON.xlsx\n",
      "✓ Completed analysis for CH-Dav\n",
      "\n",
      "==================================================\n",
      "Processing HOLAPS station: CH-Fru\n",
      "==================================================\n",
      "Loading HOLAPS data for CH-Fru...\n",
      "Data period: 2001 to 2020\n",
      "Total years: 20\n",
      "HOLAPS variable availability saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\CH-Fru\\CH-Fru_holaps_variable_availability.csv\n",
      "Performing yearly analysis...\n",
      "Yearly means saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\CH-Fru\\holaps_yearly_means_CH-Fru.xlsx\n",
      "Performing seasonal analysis...\n",
      "Seasonal means for DJF saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\CH-Fru\\holaps_seasonal_means_CH-Fru_DJF.xlsx\n",
      "Seasonal means for MAM saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\CH-Fru\\holaps_seasonal_means_CH-Fru_MAM.xlsx\n",
      "Seasonal means for JJA saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\CH-Fru\\holaps_seasonal_means_CH-Fru_JJA.xlsx\n",
      "Seasonal means for SON saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\CH-Fru\\holaps_seasonal_means_CH-Fru_SON.xlsx\n",
      "Performing trend analysis...\n",
      "Yearly trend tables saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\CH-Fru\\holaps_trend_tables_CH-Fru_yearly.xlsx\n",
      "Seasonal trend tables for DJF saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\CH-Fru\\holaps_trend_tables_CH-Fru_DJF.xlsx\n",
      "Seasonal trend tables for MAM saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\CH-Fru\\holaps_trend_tables_CH-Fru_MAM.xlsx\n",
      "Seasonal trend tables for JJA saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\CH-Fru\\holaps_trend_tables_CH-Fru_JJA.xlsx\n",
      "Seasonal trend tables for SON saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\CH-Fru\\holaps_trend_tables_CH-Fru_SON.xlsx\n",
      "✓ Completed analysis for CH-Fru\n",
      "\n",
      "==================================================\n",
      "Processing HOLAPS station: CZ-BK1\n",
      "==================================================\n",
      "Loading HOLAPS data for CZ-BK1...\n",
      "Data period: 2001 to 2020\n",
      "Total years: 20\n",
      "HOLAPS variable availability saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\CZ-BK1\\CZ-BK1_holaps_variable_availability.csv\n",
      "Performing yearly analysis...\n",
      "Yearly means saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\CZ-BK1\\holaps_yearly_means_CZ-BK1.xlsx\n",
      "Performing seasonal analysis...\n",
      "Seasonal means for DJF saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\CZ-BK1\\holaps_seasonal_means_CZ-BK1_DJF.xlsx\n",
      "Seasonal means for MAM saved to c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\\CZ-BK1\\holaps_seasonal_means_CZ-BK1_MAM.xlsx\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chinthap\\AppData\\Local\\miniconda3\\envs\\new\\Lib\\site-packages\\et_xmlfile\\incremental_tree.py:873\u001b[39m, in \u001b[36m_get_writer\u001b[39m\u001b[34m(file_or_filename, encoding)\u001b[39m\n\u001b[32m    872\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m     write = \u001b[43mfile_or_filename\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[32m    875\u001b[39m     \u001b[38;5;66;03m# file_or_filename is a file name\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'write'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 508\u001b[39m\n\u001b[32m    502\u001b[39m \u001b[38;5;66;03m# Run for specific station\u001b[39;00m\n\u001b[32m    503\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    504\u001b[39m     \u001b[38;5;66;03m# Run for a single station\u001b[39;00m\n\u001b[32m    505\u001b[39m     \u001b[38;5;66;03m# run_holaps_analysis(\"FR-Hes\")\u001b[39;00m\n\u001b[32m    506\u001b[39m \n\u001b[32m    507\u001b[39m     \u001b[38;5;66;03m# Or run for all available stations\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m508\u001b[39m     \u001b[43mrun_all_holaps_stations\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 497\u001b[39m, in \u001b[36mrun_all_holaps_stations\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    494\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m50\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    496\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m497\u001b[39m     \u001b[43mrun_holaps_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    498\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✓ Completed analysis for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstation\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    499\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 439\u001b[39m, in \u001b[36mrun_holaps_analysis\u001b[39m\u001b[34m(station_code)\u001b[39m\n\u001b[32m    436\u001b[39m seasonal_file = os.path.join(output_dir, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mholaps_seasonal_means_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstation_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseason\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.xlsx\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    438\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m seasonal_results:\n\u001b[32m--> \u001b[39m\u001b[32m439\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mExcelWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseasonal_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mseasonal_results\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mempty\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chinthap\\AppData\\Local\\miniconda3\\envs\\new\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1353\u001b[39m, in \u001b[36mExcelWriter.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_value, traceback)\u001b[39m\n\u001b[32m   1347\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\n\u001b[32m   1348\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1349\u001b[39m     exc_type: \u001b[38;5;28mtype\u001b[39m[\u001b[38;5;167;01mBaseException\u001b[39;00m] | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1350\u001b[39m     exc_value: \u001b[38;5;167;01mBaseException\u001b[39;00m | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1351\u001b[39m     traceback: TracebackType | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1352\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1353\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chinthap\\AppData\\Local\\miniconda3\\envs\\new\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1357\u001b[39m, in \u001b[36mExcelWriter.close\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1355\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclose\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1356\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"synonym for save, to make it more file-like\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1357\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1358\u001b[39m     \u001b[38;5;28mself\u001b[39m._handles.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chinthap\\AppData\\Local\\miniconda3\\envs\\new\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:110\u001b[39m, in \u001b[36mOpenpyxlWriter._save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_save\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    107\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[33;03m    Save workbook to disk.\u001b[39;00m\n\u001b[32m    109\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handles\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mr+\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._handles.handle, mmap.mmap):\n\u001b[32m    112\u001b[39m         \u001b[38;5;66;03m# truncate file to the written content\u001b[39;00m\n\u001b[32m    113\u001b[39m         \u001b[38;5;28mself\u001b[39m._handles.handle.truncate()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chinthap\\AppData\\Local\\miniconda3\\envs\\new\\Lib\\site-packages\\openpyxl\\workbook\\workbook.py:386\u001b[39m, in \u001b[36mWorkbook.save\u001b[39m\u001b[34m(self, filename)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.write_only \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.worksheets:\n\u001b[32m    385\u001b[39m     \u001b[38;5;28mself\u001b[39m.create_sheet()\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m \u001b[43msave_workbook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chinthap\\AppData\\Local\\miniconda3\\envs\\new\\Lib\\site-packages\\openpyxl\\writer\\excel.py:294\u001b[39m, in \u001b[36msave_workbook\u001b[39m\u001b[34m(workbook, filename)\u001b[39m\n\u001b[32m    292\u001b[39m workbook.properties.modified = datetime.datetime.now(tz=datetime.timezone.utc).replace(tzinfo=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    293\u001b[39m writer = ExcelWriter(workbook, archive)\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m \u001b[43mwriter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chinthap\\AppData\\Local\\miniconda3\\envs\\new\\Lib\\site-packages\\openpyxl\\writer\\excel.py:275\u001b[39m, in \u001b[36mExcelWriter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msave\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    274\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Write data into the archive.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwrite_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    276\u001b[39m     \u001b[38;5;28mself\u001b[39m._archive.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chinthap\\AppData\\Local\\miniconda3\\envs\\new\\Lib\\site-packages\\openpyxl\\writer\\excel.py:77\u001b[39m, in \u001b[36mExcelWriter.write_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     74\u001b[39m     custom_override = CustomOverride()\n\u001b[32m     75\u001b[39m     \u001b[38;5;28mself\u001b[39m.manifest.append(custom_override)\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_write_worksheets\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[38;5;28mself\u001b[39m._write_chartsheets()\n\u001b[32m     79\u001b[39m \u001b[38;5;28mself\u001b[39m._write_images()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chinthap\\AppData\\Local\\miniconda3\\envs\\new\\Lib\\site-packages\\openpyxl\\writer\\excel.py:215\u001b[39m, in \u001b[36mExcelWriter._write_worksheets\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, ws \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.workbook.worksheets, \u001b[32m1\u001b[39m):\n\u001b[32m    214\u001b[39m     ws._id = idx\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwrite_worksheet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mws\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ws._drawing:\n\u001b[32m    218\u001b[39m         \u001b[38;5;28mself\u001b[39m._write_drawing(ws._drawing)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chinthap\\AppData\\Local\\miniconda3\\envs\\new\\Lib\\site-packages\\openpyxl\\writer\\excel.py:200\u001b[39m, in \u001b[36mExcelWriter.write_worksheet\u001b[39m\u001b[34m(self, ws)\u001b[39m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    199\u001b[39m     writer = WorksheetWriter(ws)\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m     \u001b[43mwriter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m ws._rels = writer._rels\n\u001b[32m    203\u001b[39m \u001b[38;5;28mself\u001b[39m._archive.write(writer.out, ws.path[\u001b[32m1\u001b[39m:])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chinthap\\AppData\\Local\\miniconda3\\envs\\new\\Lib\\site-packages\\openpyxl\\worksheet\\_writer.py:361\u001b[39m, in \u001b[36mWorksheetWriter.write\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    359\u001b[39m \u001b[38;5;28mself\u001b[39m.write_rows()\n\u001b[32m    360\u001b[39m \u001b[38;5;28mself\u001b[39m.write_tail()\n\u001b[32m--> \u001b[39m\u001b[32m361\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chinthap\\AppData\\Local\\miniconda3\\envs\\new\\Lib\\site-packages\\openpyxl\\worksheet\\_writer.py:369\u001b[39m, in \u001b[36mWorksheetWriter.close\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    365\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    366\u001b[39m \u001b[33;03mClose the context manager\u001b[39;00m\n\u001b[32m    367\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    368\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.xf:\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mxf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chinthap\\AppData\\Local\\miniconda3\\envs\\new\\Lib\\site-packages\\openpyxl\\worksheet\\_writer.py:288\u001b[39m, in \u001b[36mWorksheetWriter.get_stream\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_stream\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mxmlfile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mxf\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mxf\u001b[49m\u001b[43m.\u001b[49m\u001b[43melement\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mworksheet\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxmlns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSHEET_MAIN_NS\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chinthap\\AppData\\Local\\miniconda3\\envs\\new\\Lib\\site-packages\\et_xmlfile\\xmlfile.py:156\u001b[39m, in \u001b[36mxmlfile.__exit__\u001b[39m\u001b[34m(self, type, value, traceback)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mtype\u001b[39m, value, traceback):\n\u001b[32m    155\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.writer_cm:\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwriter_cm\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__exit__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._close:\n\u001b[32m    158\u001b[39m         \u001b[38;5;28mself\u001b[39m._file.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chinthap\\AppData\\Local\\miniconda3\\envs\\new\\Lib\\contextlib.py:148\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m         \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    150\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chinthap\\AppData\\Local\\miniconda3\\envs\\new\\Lib\\site-packages\\et_xmlfile\\incremental_tree.py:878\u001b[39m, in \u001b[36m_get_writer\u001b[39m\u001b[34m(file_or_filename, encoding)\u001b[39m\n\u001b[32m    876\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m encoding.lower() == \u001b[33m\"\u001b[39m\u001b[33municode\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    877\u001b[39m         encoding = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_or_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mw\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m              \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mxmlcharrefreplace\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    882\u001b[39m     \u001b[38;5;66;03m# file_or_filename is a file-like object\u001b[39;00m\n\u001b[32m    883\u001b[39m     \u001b[38;5;66;03m# encoding determines if it is a text or binary writer\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymannkendall as mk\n",
    "import os\n",
    "from typing import Dict, List, Tuple\n",
    "import glob\n",
    "\n",
    "# ======================\n",
    "# DATA PROCESSING MODULE\n",
    "# ======================\n",
    "\n",
    "def load_holaps_data(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load HOLAPS model data and prepare for analysis\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to HOLAPS CSV file\n",
    "    \n",
    "    Returns:\n",
    "        Processed DataFrame with additional columns\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Convert temperature from Kelvin to Celsius if needed\n",
    "    temp_cols = ['Ta', 'Td', 'Ts']\n",
    "    for col in temp_cols:\n",
    "        if col in df.columns:\n",
    "            # Assuming temperatures are in Kelvin, convert to Celsius\n",
    "            df[col] = df[col] - 273.15\n",
    "    \n",
    "    # Create datetime column for easier time-based operations\n",
    "    df['date'] = pd.to_datetime(df[['year', 'month']].assign(day=1))\n",
    "    df['Year'] = df['year']\n",
    "    df['Month'] = df['month']\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ======================\n",
    "# COMPLETENESS ANALYSIS\n",
    "# ======================\n",
    "\n",
    "def validate_holaps_variable(df: pd.DataFrame, var: str) -> List[int]:\n",
    "    \"\"\"\n",
    "    Identify complete years for a HOLAPS variable\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame with data\n",
    "        var: Variable name to validate\n",
    "    \n",
    "    Returns:\n",
    "        List of years with complete data (12 months)\n",
    "    \"\"\"\n",
    "    # HOLAPS data typically doesn't have QC flags, just check for non-NaN values\n",
    "    valid_mask = df[var].notna()\n",
    "    \n",
    "    valid_data = df[valid_mask].copy()\n",
    "    valid_year_counts = valid_data['Year'].value_counts()\n",
    "    return valid_year_counts[valid_year_counts == 12].index.tolist()\n",
    "\n",
    "def get_complete_years_holaps(df: pd.DataFrame, variables: List[str]) -> List[int]:\n",
    "    \"\"\"\n",
    "    Find years where all specified variables have complete data\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame with data\n",
    "        variables: List of variables to check\n",
    "    \n",
    "    Returns:\n",
    "        Sorted list of years with complete data for all variables\n",
    "    \"\"\"\n",
    "    common_years = set(df['Year'].unique())\n",
    "    for var in variables:\n",
    "        valid_years = validate_holaps_variable(df, var)\n",
    "        common_years.intersection_update(valid_years)\n",
    "    return sorted(common_years)\n",
    "\n",
    "def save_holaps_variable_availability(df: pd.DataFrame, variables: List[str], output_file: str) -> None:\n",
    "    \"\"\"\n",
    "    Save availability of each variable (years with valid data)\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with Year and variable columns\n",
    "        variables: List of variables to check\n",
    "        output_file: Path to save CSV\n",
    "    \"\"\"\n",
    "    availability_records = []\n",
    "    \n",
    "    for var in variables:\n",
    "        valid_years = validate_holaps_variable(df, var)\n",
    "        availability_records.append({\n",
    "            \"Variable\": var,\n",
    "            \"Valid_Years\": \", \".join(map(str, sorted(valid_years))),\n",
    "            \"Count_Valid_Years\": len(valid_years)\n",
    "        })\n",
    "    \n",
    "    availability_df = pd.DataFrame(availability_records)\n",
    "    availability_df.to_csv(output_file, index=False)\n",
    "    print(f\"HOLAPS variable availability saved to {output_file}\")\n",
    "\n",
    "# ======================\n",
    "# YEARLY ANALYSIS\n",
    "# ======================\n",
    "\n",
    "def calculate_holaps_yearly_means(df: pd.DataFrame, variables: List[str], years: List[int]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate yearly means for complete years only\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame with data\n",
    "        variables: Variables to calculate means for\n",
    "        years: Years to include\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with yearly means\n",
    "    \"\"\"\n",
    "    if not years:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    complete_data = df[df['Year'].isin(years)]\n",
    "    yearly_means = complete_data.groupby('Year')[variables].mean()\n",
    "    return yearly_means.reset_index()\n",
    "\n",
    "def generate_holaps_yearly_analysis(df: pd.DataFrame, variables: List[str]) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Generate yearly means for HOLAPS data\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame with data\n",
    "        variables: List of variables to analyze\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of DataFrames with yearly means\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Get complete years for all variables\n",
    "    complete_years = get_complete_years_holaps(df, variables)\n",
    "    \n",
    "    if complete_years:\n",
    "        # Calculate yearly means for complete period\n",
    "        yearly_means = calculate_holaps_yearly_means(df, variables, complete_years)\n",
    "        results[\"Complete Period\"] = yearly_means\n",
    "        \n",
    "        # Also calculate for all available years (individual variable completeness)\n",
    "        for var in variables:\n",
    "            var_years = validate_holaps_variable(df, [var])\n",
    "            if var_years:\n",
    "                var_means = calculate_holaps_yearly_means(df, [var], var_years)\n",
    "                results[f\"Single Variable - {var}\"] = var_means\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ======================\n",
    "# SEASONAL ANALYSIS\n",
    "# ======================\n",
    "\n",
    "def get_season_months(season: str) -> List[int]:\n",
    "    \"\"\"Return months for each season (with DJF year adjustment)\"\"\"\n",
    "    return {\n",
    "        'DJF': [12, 1, 2],  # December, January, February\n",
    "        'MAM': [3, 4, 5],   # March, April, May\n",
    "        'JJA': [6, 7, 8],   # June, July, August\n",
    "        'SON': [9, 10, 11]  # September, October, November\n",
    "    }[season]\n",
    "\n",
    "def get_complete_seasons_holaps(df: pd.DataFrame, variables: List[str], season: str) -> List[int]:\n",
    "    \"\"\"\n",
    "    Get seasons with complete data for all variables\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame\n",
    "        variables: Variables to check\n",
    "        season: Season code (DJF, MAM, JJA, SON)\n",
    "    \n",
    "    Returns:\n",
    "        List of complete season years\n",
    "    \"\"\"\n",
    "    season_months = get_season_months(season)\n",
    "    df_season = df[df['Month'].isin(season_months)].copy()\n",
    "    \n",
    "    # Adjust year for winter season (DJF)\n",
    "    if season == 'DJF':\n",
    "        df_season['Season_Year'] = df_season['Year']\n",
    "        df_season.loc[df_season['Month'] == 12, 'Season_Year'] += 1\n",
    "    else:\n",
    "        df_season['Season_Year'] = df_season['Year']\n",
    "    \n",
    "    # Find seasons with all months present\n",
    "    month_counts = df_season.groupby(['Season_Year'])['Month'].nunique()\n",
    "    complete_seasons = month_counts[month_counts == 3].index.tolist()\n",
    "    \n",
    "    # Check variable completeness\n",
    "    valid_seasons = []\n",
    "    for season_year in complete_seasons:\n",
    "        season_data = df_season[df_season['Season_Year'] == season_year]\n",
    "        valid = True\n",
    "        for var in variables:\n",
    "            var_data = season_data[season_data[var].notna()]\n",
    "            if len(var_data) < 3:  # Not all months valid\n",
    "                valid = False\n",
    "                break\n",
    "        if valid:\n",
    "            valid_seasons.append(season_year)\n",
    "    \n",
    "    return sorted(valid_seasons)\n",
    "\n",
    "def calculate_holaps_seasonal_means(df: pd.DataFrame, variables: List[str], season: str, season_years: List[int]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate seasonal means for complete seasons\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame\n",
    "        variables: Variables to calculate means for\n",
    "        season: Season code (DJF, MAM, JJA, SON)\n",
    "        season_years: List of years with complete seasonal data\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with seasonal means\n",
    "    \"\"\"\n",
    "    if not season_years:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    season_months = get_season_months(season)\n",
    "    df_season = df[df['Month'].isin(season_months)].copy()\n",
    "    \n",
    "    # Adjust year for winter season (DJF)\n",
    "    if season == 'DJF':\n",
    "        df_season['Season_Year'] = df_season['Year']\n",
    "        df_season.loc[df_season['Month'] == 12, 'Season_Year'] += 1\n",
    "    else:\n",
    "        df_season['Season_Year'] = df_season['Year']\n",
    "    \n",
    "    # Filter for complete seasons\n",
    "    df_season = df_season[df_season['Season_Year'].isin(season_years)]\n",
    "    \n",
    "    # Calculate seasonal means\n",
    "    seasonal_means = df_season.groupby('Season_Year')[variables].mean()\n",
    "    seasonal_means['Season'] = season\n",
    "    return seasonal_means.reset_index()\n",
    "\n",
    "def generate_holaps_seasonal_analysis(df: pd.DataFrame, variables: List[str], season: str) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Generate seasonal means for HOLAPS data\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame\n",
    "        variables: Variables to analyze\n",
    "        season: Season code (DJF, MAM, JJA, SON)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of DataFrames with seasonal means\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Get complete seasons for all variables\n",
    "    complete_seasons = get_complete_seasons_holaps(df, variables, season)\n",
    "    \n",
    "    if complete_seasons:\n",
    "        # Calculate seasonal means for complete period\n",
    "        seasonal_means = calculate_holaps_seasonal_means(df, variables, season, complete_seasons)\n",
    "        results[\"Complete Period\"] = seasonal_means\n",
    "        \n",
    "        # Also calculate for all available seasons (individual variable completeness)\n",
    "        for var in variables:\n",
    "            # For single variable, we can be less strict about completeness\n",
    "            var_season_data = df[df['Month'].isin(get_season_months(season))].copy()\n",
    "            \n",
    "            # Adjust year for winter season\n",
    "            if season == 'DJF':\n",
    "                var_season_data['Season_Year'] = var_season_data['Year']\n",
    "                var_season_data.loc[var_season_data['Month'] == 12, 'Season_Year'] += 1\n",
    "            else:\n",
    "                var_season_data['Season_Year'] = var_season_data['Year']\n",
    "            \n",
    "            # Filter for seasons with this variable available\n",
    "            var_valid = var_season_data[var_season_data[var].notna()]\n",
    "            var_season_counts = var_valid.groupby('Season_Year').size()\n",
    "            var_complete_seasons = var_season_counts[var_season_counts == 3].index.tolist()\n",
    "            \n",
    "            if var_complete_seasons:\n",
    "                var_means = calculate_holaps_seasonal_means(df, [var], season, var_complete_seasons)\n",
    "                results[f\"Single Variable - {var}\"] = var_means\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ======================\n",
    "# TREND ANALYSIS\n",
    "# ======================\n",
    "\n",
    "def calculate_holaps_trend_stats(series: pd.Series) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculate Mann-Kendall trend statistics for HOLAPS data\n",
    "    \n",
    "    Args:\n",
    "        series: Time series data with Year as index\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with slope, p-value, and period info\n",
    "    \"\"\"\n",
    "    if series.notna().sum() < 10:\n",
    "        return None\n",
    "    \n",
    "    start_year = int(series.index.min())\n",
    "    end_year = int(series.index.max())\n",
    "    full_index = np.arange(start_year, end_year + 1, 1)\n",
    "    series = series.reindex(full_index)\n",
    "    \n",
    "    try:\n",
    "        result = mk.original_test(series.values)\n",
    "        return {\n",
    "            'slope': result.slope,\n",
    "            'p_value': result.p,\n",
    "            'period': f\"{start_year}-{end_year} ({series.notna().sum()})\"\n",
    "        }\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def build_holaps_trend_tables(sheets: Dict[str, pd.DataFrame]) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Build p-value and slope tables from HOLAPS analysis results\n",
    "    \n",
    "    Args:\n",
    "        sheets: Dictionary of DataFrames from analysis\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (p-value table, slope table)\n",
    "    \"\"\"\n",
    "    p_table_data = []\n",
    "    slope_table_data = []\n",
    "    \n",
    "    for sheet_name, data in sheets.items():\n",
    "        if data.empty:\n",
    "            continue\n",
    "            \n",
    "        # Set appropriate index\n",
    "        if 'Year' in data.columns:\n",
    "            data_indexed = data.set_index('Year')\n",
    "        elif 'Season_Year' in data.columns:\n",
    "            data_indexed = data.set_index('Season_Year')\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        # Get variables (exclude metadata columns)\n",
    "        vars_included = [col for col in data_indexed.columns if col not in ['Season', 'station_id', 'latitude', 'longitude']]\n",
    "        \n",
    "        # Calculate stats for all variables\n",
    "        stats_dict = {}\n",
    "        period = None\n",
    "        \n",
    "        for var in vars_included:\n",
    "            stats = calculate_holaps_trend_stats(data_indexed[var].dropna())\n",
    "            if stats:\n",
    "                stats_dict[var] = {\n",
    "                    'p_value': stats['p_value'],\n",
    "                    'slope': stats['slope']\n",
    "                }\n",
    "                period = stats['period']\n",
    "        \n",
    "        if stats_dict:\n",
    "            p_row = {'Analysis': sheet_name, 'Period': period}\n",
    "            s_row = {'Analysis': sheet_name, 'Period': period}\n",
    "            \n",
    "            for var in vars_included:\n",
    "                if var in stats_dict:\n",
    "                    p_row[var] = stats_dict[var]['p_value']\n",
    "                    s_row[var] = stats_dict[var]['slope']\n",
    "                else:\n",
    "                    p_row[var] = np.nan\n",
    "                    s_row[var] = np.nan\n",
    "            \n",
    "            p_table_data.append(p_row)\n",
    "            slope_table_data.append(s_row)\n",
    "    \n",
    "    return pd.DataFrame(p_table_data), pd.DataFrame(slope_table_data)\n",
    "\n",
    "# ======================\n",
    "# MAIN EXECUTION\n",
    "# ======================\n",
    "\n",
    "def run_holaps_analysis(station_code: str):\n",
    "    \"\"\"\n",
    "    Run complete HOLAPS analysis pipeline\n",
    "    \n",
    "    Args:\n",
    "        station_code: Station code (e.g., \"FR-Hes\")\n",
    "    \"\"\"\n",
    "    # Define HOLAPS variables\n",
    "    holaps_variables = ['GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1','sm2','sm3','sm4','sm5']\n",
    "    \n",
    "    # Build file path\n",
    "    base_dir = r\"c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\"\n",
    "   \n",
    "    holaps_file = os.path.join(base_dir, f\"{station_code}_all_variables.csv\")\n",
    "    \n",
    "    # Check if file exists\n",
    "    if not os.path.exists(holaps_file):\n",
    "        print(f\"HOLAPS file not found for {station_code}: {holaps_file}\")\n",
    "        return\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = os.path.join(base_dir, station_code)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Load data\n",
    "    print(f\"Loading HOLAPS data for {station_code}...\")\n",
    "    df = load_holaps_data(holaps_file)\n",
    "    \n",
    "    # Basic info\n",
    "    print(f\"Data period: {df['Year'].min()} to {df['Year'].max()}\")\n",
    "    print(f\"Total years: {df['Year'].nunique()}\")\n",
    "    \n",
    "    # Save variable availability\n",
    "    availability_file = os.path.join(output_dir, f\"{station_code}_holaps_variable_availability.csv\")\n",
    "    save_holaps_variable_availability(df, holaps_variables, availability_file)\n",
    "    \n",
    "    # Yearly analysis\n",
    "    print(\"Performing yearly analysis...\")\n",
    "    yearly_results = generate_holaps_yearly_analysis(df, holaps_variables)\n",
    "    \n",
    "    yearly_file = os.path.join(output_dir, f'holaps_yearly_means_{station_code}.xlsx')\n",
    "    if yearly_results:\n",
    "        with pd.ExcelWriter(yearly_file) as writer:\n",
    "            for sheet_name, data in yearly_results.items():\n",
    "                if not data.empty:\n",
    "                    data.to_excel(writer, sheet_name=sheet_name[:31], index=False)\n",
    "        print(f\"Yearly means saved to {yearly_file}\")\n",
    "    else:\n",
    "        print(\"No complete yearly data available\")\n",
    "    \n",
    "    # Seasonal analysis\n",
    "    print(\"Performing seasonal analysis...\")\n",
    "    seasons = ['DJF', 'MAM', 'JJA', 'SON']\n",
    "    \n",
    "    for season in seasons:\n",
    "        seasonal_results = generate_holaps_seasonal_analysis(df, holaps_variables, season)\n",
    "        seasonal_file = os.path.join(output_dir, f\"holaps_seasonal_means_{station_code}_{season}.xlsx\")\n",
    "        \n",
    "        if seasonal_results:\n",
    "            with pd.ExcelWriter(seasonal_file) as writer:\n",
    "                for sheet_name, data in seasonal_results.items():\n",
    "                    if not data.empty:\n",
    "                        data.to_excel(writer, sheet_name=sheet_name[:31], index=False)\n",
    "            print(f\"Seasonal means for {season} saved to {seasonal_file}\")\n",
    "        else:\n",
    "            print(f\"No complete seasonal data available for {season}\")\n",
    "    \n",
    "    # Trend analysis - Yearly\n",
    "    print(\"Performing trend analysis...\")\n",
    "    if os.path.exists(yearly_file):\n",
    "        yearly_sheets = pd.read_excel(yearly_file, sheet_name=None)\n",
    "        p_table, slope_table = build_holaps_trend_tables(yearly_sheets)\n",
    "        \n",
    "        trend_file = os.path.join(output_dir, f'holaps_trend_tables_{station_code}_yearly.xlsx')\n",
    "        with pd.ExcelWriter(trend_file) as writer:\n",
    "            p_table.to_excel(writer, sheet_name='P-values', index=False)\n",
    "            slope_table.to_excel(writer, sheet_name='Slopes', index=False)\n",
    "        print(f\"Yearly trend tables saved to {trend_file}\")\n",
    "    \n",
    "    # Trend analysis - Seasonal\n",
    "    for season in seasons:\n",
    "        seasonal_file = os.path.join(output_dir, f\"holaps_seasonal_means_{station_code}_{season}.xlsx\")\n",
    "        if os.path.exists(seasonal_file):\n",
    "            try:\n",
    "                seasonal_sheets = pd.read_excel(seasonal_file, sheet_name=None)\n",
    "                p_table, slope_table = build_holaps_trend_tables(seasonal_sheets)\n",
    "                \n",
    "                trend_file = os.path.join(output_dir, f'holaps_trend_tables_{station_code}_{season}.xlsx')\n",
    "                with pd.ExcelWriter(trend_file) as writer:\n",
    "                    p_table.to_excel(writer, sheet_name='P-values', index=False)\n",
    "                    slope_table.to_excel(writer, sheet_name='Slopes', index=False)\n",
    "                print(f\"Seasonal trend tables for {season} saved to {trend_file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing seasonal trends for {season}: {e}\")\n",
    "\n",
    "def run_all_holaps_stations():\n",
    "    base_dir = r\"c:\\\\Deepak\\\\HOLAPS\\\\monthly\\\\station_data2\"\n",
    "    \n",
    "    # Changed pattern to find all_variables files\n",
    "    holaps_files = glob.glob(os.path.join(base_dir, \"*_all_variables.csv\"))\n",
    "    \n",
    "    # Extract station codes from filenames like \"BE-Bra_all_variables.csv\"\n",
    "    stations = []\n",
    "    for file_path in holaps_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        station_code = filename.replace(\"_all_variables.csv\", \"\")\n",
    "        stations.append(station_code)\n",
    "    \n",
    "    print(f\"Found {len(stations)} HOLAPS stations: {stations}\")\n",
    "    \n",
    "    # Run analysis for each station\n",
    "    for station in stations:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Processing HOLAPS station: {station}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        try:\n",
    "            run_holaps_analysis(station)\n",
    "            print(f\"✓ Completed analysis for {station}\")\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error processing {station}: {e}\")\n",
    "\n",
    "# Run for specific station\n",
    "if __name__ == \"__main__\":\n",
    "    # Run for a single station\n",
    "    # run_holaps_analysis(\"FR-Hes\")\n",
    "    \n",
    "    # Or run for all available stations\n",
    "    run_all_holaps_stations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05cee16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows\n",
      " Volume Serial Number is 7822-CCB4\n",
      "\n",
      " Directory of c:\\Deepak\\HOLAPS\\monthly\\station_data2\n",
      "\n",
      "10/22/2025  11:11 AM    <DIR>          .\n",
      "10/21/2025  06:23 PM    <DIR>          ..\n",
      "10/22/2025  11:07 AM    <DIR>          AT-Neu\n",
      "10/21/2025  06:23 PM            81,298 AT-Neu_all_variables.csv\n",
      "10/22/2025  11:07 AM    <DIR>          BE-Bra\n",
      "10/21/2025  06:23 PM            80,459 BE-Bra_all_variables.csv\n",
      "10/22/2025  11:07 AM    <DIR>          BE-Lon\n",
      "10/21/2025  06:23 PM            81,526 BE-Lon_all_variables.csv\n",
      "10/22/2025  11:07 AM    <DIR>          BE-Vie\n",
      "10/21/2025  06:23 PM            80,880 BE-Vie_all_variables.csv\n",
      "10/22/2025  11:07 AM    <DIR>          CH-Cha\n",
      "10/21/2025  06:24 PM            80,372 CH-Cha_all_variables.csv\n",
      "10/22/2025  11:07 AM    <DIR>          CH-Dav\n",
      "10/21/2025  06:24 PM            80,457 CH-Dav_all_variables.csv\n",
      "10/22/2025  11:07 AM    <DIR>          CH-Fru\n",
      "10/21/2025  06:24 PM            81,218 CH-Fru_all_variables.csv\n",
      "10/22/2025  11:07 AM    <DIR>          CZ-BK1\n",
      "10/21/2025  06:24 PM            79,225 CZ-BK1_all_variables.csv\n",
      "10/22/2025  11:07 AM    <DIR>          CZ-wet\n",
      "10/21/2025  06:24 PM            77,581 CZ-wet_all_variables.csv\n",
      "10/22/2025  11:08 AM    <DIR>          DE-Geb\n",
      "10/21/2025  06:25 PM            81,089 DE-Geb_all_variables.csv\n",
      "10/22/2025  11:08 AM    <DIR>          DE-Gri\n",
      "10/21/2025  06:25 PM            80,951 DE-Gri_all_variables.csv\n",
      "10/22/2025  11:08 AM    <DIR>          DE-Hai\n",
      "10/21/2025  06:25 PM            81,432 DE-Hai_all_variables.csv\n",
      "10/22/2025  11:08 AM    <DIR>          DE-HoH\n",
      "10/21/2025  06:25 PM            81,406 DE-HoH_all_variables.csv\n",
      "10/22/2025  11:08 AM    <DIR>          DE-Hzd\n",
      "10/21/2025  06:25 PM            80,961 DE-Hzd_all_variables.csv\n",
      "10/22/2025  11:08 AM    <DIR>          DE-Kli\n",
      "10/21/2025  06:26 PM            81,148 DE-Kli_all_variables.csv\n",
      "10/22/2025  11:08 AM    <DIR>          DE-Lnf\n",
      "10/21/2025  06:26 PM            81,229 DE-Lnf_all_variables.csv\n",
      "10/22/2025  11:08 AM    <DIR>          DE-Obe\n",
      "10/21/2025  06:26 PM            80,678 DE-Obe_all_variables.csv\n",
      "10/22/2025  11:08 AM    <DIR>          DE-RuR\n",
      "10/21/2025  06:26 PM            81,354 DE-RuR_all_variables.csv\n",
      "10/22/2025  11:08 AM    <DIR>          DE-RuS\n",
      "10/21/2025  06:26 PM            82,464 DE-RuS_all_variables.csv\n",
      "10/22/2025  11:08 AM    <DIR>          DE-Tha\n",
      "10/21/2025  06:27 PM            80,460 DE-Tha_all_variables.csv\n",
      "10/22/2025  11:08 AM    <DIR>          DK-Sor\n",
      "10/21/2025  06:27 PM            79,101 DK-Sor_all_variables.csv\n",
      "10/22/2025  11:08 AM    <DIR>          ES-Agu\n",
      "10/21/2025  06:27 PM            81,949 ES-Agu_all_variables.csv\n",
      "10/22/2025  11:08 AM    <DIR>          ES-LJu\n",
      "10/21/2025  06:27 PM            81,553 ES-LJu_all_variables.csv\n",
      "10/22/2025  11:08 AM    <DIR>          FI-Hyy\n",
      "10/21/2025  06:27 PM            48,082 FI-Hyy_all_variables.csv\n",
      "10/22/2025  11:08 AM    <DIR>          FI-Let\n",
      "10/21/2025  06:27 PM            50,636 FI-Let_all_variables.csv\n",
      "10/22/2025  11:08 AM    <DIR>          FR-Aur\n",
      "10/21/2025  06:28 PM            81,141 FR-Aur_all_variables.csv\n",
      "10/22/2025  11:08 AM    <DIR>          FR-Bil\n",
      "10/21/2025  06:28 PM            78,625 FR-Bil_all_variables.csv\n",
      "10/22/2025  11:08 AM    <DIR>          FR-Gri\n",
      "10/21/2025  06:28 PM            81,113 FR-Gri_all_variables.csv\n",
      "10/22/2025  11:08 AM    <DIR>          FR-Hes\n",
      "10/21/2025  06:28 PM            80,395 FR-Hes_all_variables.csv\n",
      "10/22/2025  11:08 AM    <DIR>          FR-Lam\n",
      "10/21/2025  06:29 PM            77,812 FR-Lam_all_variables.csv\n",
      "10/22/2025  11:08 AM    <DIR>          FR-LBr\n",
      "10/21/2025  06:29 PM            81,109 FR-LBr_all_variables.csv\n",
      "10/22/2025  11:08 AM    <DIR>          IT-BCi\n",
      "10/21/2025  06:29 PM            77,984 IT-BCi_all_variables.csv\n",
      "10/22/2025  11:09 AM    <DIR>          IT-Col\n",
      "10/21/2025  06:29 PM            80,849 IT-Col_all_variables.csv\n",
      "10/22/2025  11:09 AM    <DIR>          IT-Cp2\n",
      "10/21/2025  06:30 PM            75,858 IT-Cp2_all_variables.csv\n",
      "10/22/2025  11:09 AM    <DIR>          IT-Cpz\n",
      "10/21/2025  06:29 PM            74,262 IT-Cpz_all_variables.csv\n",
      "10/22/2025  11:09 AM    <DIR>          IT-Lav\n",
      "10/21/2025  06:29 PM            80,692 IT-Lav_all_variables.csv\n",
      "10/22/2025  11:09 AM    <DIR>          IT-MBo\n",
      "10/21/2025  06:30 PM            78,213 IT-MBo_all_variables.csv\n",
      "10/22/2025  11:09 AM    <DIR>          IT-Ren\n",
      "10/21/2025  06:30 PM            80,815 IT-Ren_all_variables.csv\n",
      "10/22/2025  11:09 AM    <DIR>          IT-Ro2\n",
      "10/21/2025  06:30 PM            80,983 IT-Ro2_all_variables.csv\n",
      "10/22/2025  11:09 AM    <DIR>          IT-SR2\n",
      "10/21/2025  06:30 PM            71,589 IT-SR2_all_variables.csv\n",
      "10/22/2025  11:09 AM    <DIR>          IT-SRo\n",
      "10/21/2025  06:31 PM            71,589 IT-SRo_all_variables.csv\n",
      "10/22/2025  11:09 AM    <DIR>          IT-Tor\n",
      "10/21/2025  06:31 PM            80,871 IT-Tor_all_variables.csv\n",
      "10/22/2025  11:09 AM    <DIR>          IT-TrF\n",
      "10/21/2025  06:31 PM            80,440 IT-TrF_all_variables.csv\n",
      "10/22/2025  11:09 AM    <DIR>          NL-Loo\n",
      "10/21/2025  06:31 PM            81,835 NL-Loo_all_variables.csv\n",
      "10/22/2025  11:11 AM    <DIR>          plots\n",
      "10/22/2025  11:09 AM    <DIR>          RU-Fyo\n",
      "10/21/2025  06:32 PM            80,932 RU-Fyo_all_variables.csv\n",
      "10/22/2025  11:09 AM    <DIR>          SE-Htm\n",
      "10/21/2025  06:31 PM            81,446 SE-Htm_all_variables.csv\n",
      "10/22/2025  11:09 AM    <DIR>          SE-Nor\n",
      "10/21/2025  06:32 PM            52,404 SE-Nor_all_variables.csv\n",
      "10/22/2025  11:06 AM            83,818 station_wise_analysis_holaps.ipynb\n",
      "              48 File(s)      3,752,284 bytes\n",
      "              50 Dir(s)  753,864,642,560 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5507e5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 48 station directories\n",
      "Processing AT-Neu...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=0.0002, p-value=0.9741\n",
      "    H: slope=0.0088, p-value=0.6265\n",
      "    LE: slope=0.0136, p-value=0.8203\n",
      "    Rn: slope=0.0336, p-value=0.6732\n",
      "    Ta: slope=0.0636, p-value=0.0150\n",
      "    Td: slope=0.0679, p-value=0.0179\n",
      "    Ts: slope=0.0683, p-value=0.0179\n",
      "    rain: slope=-0.0004, p-value=0.8203\n",
      "    sm1: slope=-0.0002, p-value=0.3145\n",
      "✓ HOLAPS trend plot saved for AT-Neu\n",
      "Processing BE-Bra...\n",
      "  P-values shape: (1, 11)\n",
      "  Slopes shape: (1, 11)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=-0.0019, p-value=0.8711\n",
      "    H: slope=0.1633, p-value=0.1119\n",
      "    LE: slope=0.0276, p-value=0.4957\n",
      "    Rn: slope=0.1380, p-value=0.2300\n",
      "    Ta: slope=0.0524, p-value=0.0212\n",
      "    Td: slope=0.0631, p-value=0.0252\n",
      "    Ts: slope=0.0626, p-value=0.0212\n",
      "    rain: slope=-0.0020, p-value=0.0478\n",
      "    sm1: slope=-0.0004, p-value=0.0212\n",
      "✓ HOLAPS trend plot saved for BE-Bra\n",
      "Processing BE-Lon...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=-0.0027, p-value=0.7212\n",
      "    H: slope=0.0399, p-value=0.3145\n",
      "    LE: slope=0.1241, p-value=0.4555\n",
      "    Rn: slope=0.2469, p-value=0.1443\n",
      "    Ta: slope=0.0550, p-value=0.0212\n",
      "    Td: slope=0.0633, p-value=0.0410\n",
      "    Ts: slope=0.0628, p-value=0.0478\n",
      "    rain: slope=0.0010, p-value=0.3468\n",
      "    sm1: slope=-0.0006, p-value=0.5376\n",
      "✓ HOLAPS trend plot saved for BE-Lon\n",
      "Processing BE-Vie...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=-0.0017, p-value=0.5376\n",
      "    H: slope=0.0652, p-value=0.4555\n",
      "    LE: slope=0.1929, p-value=0.0297\n",
      "    Rn: slope=0.2543, p-value=0.1443\n",
      "    Ta: slope=0.0562, p-value=0.0179\n",
      "    Td: slope=0.0682, p-value=0.0297\n",
      "    Ts: slope=0.0678, p-value=0.0252\n",
      "    rain: slope=0.0002, p-value=0.8203\n",
      "    sm1: slope=-0.0004, p-value=0.2300\n",
      "✓ HOLAPS trend plot saved for BE-Vie\n",
      "Processing CH-Cha...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=-0.0019, p-value=0.6732\n",
      "    H: slope=-0.0094, p-value=0.9741\n",
      "    LE: slope=0.3829, p-value=0.0086\n",
      "    Rn: slope=0.3279, p-value=0.0104\n",
      "    Ta: slope=0.0560, p-value=0.0297\n",
      "    Td: slope=0.0569, p-value=0.0980\n",
      "    Ts: slope=0.0576, p-value=0.1119\n",
      "    rain: slope=0.0026, p-value=0.0010\n",
      "    sm1: slope=0.0009, p-value=0.0855\n",
      "✓ HOLAPS trend plot saved for CH-Cha\n",
      "Processing CH-Dav...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=-0.0007, p-value=0.9225\n",
      "    H: slope=-0.0175, p-value=0.5813\n",
      "    LE: slope=0.1698, p-value=0.0556\n",
      "    Rn: slope=0.0914, p-value=0.4555\n",
      "    Ta: slope=0.0668, p-value=0.0179\n",
      "    Td: slope=0.0683, p-value=0.0252\n",
      "    Ts: slope=0.0700, p-value=0.0179\n",
      "    rain: slope=0.0017, p-value=0.0478\n",
      "    sm1: slope=0.0005, p-value=0.1834\n",
      "✓ HOLAPS trend plot saved for CH-Dav\n",
      "Processing CH-Fru...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=-0.0014, p-value=0.6732\n",
      "    H: slope=0.0141, p-value=0.8711\n",
      "    LE: slope=0.2905, p-value=0.0026\n",
      "    Rn: slope=0.3211, p-value=0.0212\n",
      "    Ta: slope=0.0610, p-value=0.0125\n",
      "    Td: slope=0.0626, p-value=0.0252\n",
      "    Ts: slope=0.0598, p-value=0.0252\n",
      "    rain: slope=0.0032, p-value=0.0002\n",
      "    sm1: slope=0.0008, p-value=0.1443\n",
      "✓ HOLAPS trend plot saved for CH-Fru\n",
      "Processing CZ-BK1...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=0.0003, p-value=0.9741\n",
      "    H: slope=0.0443, p-value=0.5813\n",
      "    LE: slope=0.2231, p-value=0.0001\n",
      "    Rn: slope=0.2671, p-value=0.0104\n",
      "    Ta: slope=0.0854, p-value=0.0048\n",
      "    Td: slope=0.0823, p-value=0.0125\n",
      "    Ts: slope=0.0795, p-value=0.0125\n",
      "    rain: slope=0.0018, p-value=0.0350\n",
      "    sm1: slope=0.0005, p-value=0.2058\n",
      "✓ HOLAPS trend plot saved for CZ-BK1\n",
      "Processing CZ-wet...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=-0.0007, p-value=0.9225\n",
      "    H: slope=-0.0331, p-value=0.8203\n",
      "    LE: slope=0.1952, p-value=0.0150\n",
      "    Rn: slope=0.2883, p-value=0.0252\n",
      "    Ta: slope=0.0749, p-value=0.0048\n",
      "    Td: slope=0.0839, p-value=0.0048\n",
      "    Ts: slope=0.0875, p-value=0.0058\n",
      "    rain: slope=-0.0007, p-value=0.3145\n",
      "    sm1: slope=-0.0004, p-value=0.3145\n",
      "✓ HOLAPS trend plot saved for CZ-wet\n",
      "Processing DE-Geb...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=-0.0000, p-value=1.0000\n",
      "    H: slope=0.0544, p-value=0.6732\n",
      "    LE: slope=0.3141, p-value=0.0007\n",
      "    Rn: slope=0.4265, p-value=0.0104\n",
      "    Ta: slope=0.0699, p-value=0.0026\n",
      "    Td: slope=0.0873, p-value=0.0086\n",
      "    Ts: slope=0.0855, p-value=0.0086\n",
      "    rain: slope=0.0004, p-value=0.7703\n",
      "    sm1: slope=0.0001, p-value=0.8203\n",
      "✓ HOLAPS trend plot saved for DE-Geb\n",
      "Processing DE-Gri...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=0.0016, p-value=0.6265\n",
      "    H: slope=0.2193, p-value=0.1119\n",
      "    LE: slope=0.1802, p-value=0.0005\n",
      "    Rn: slope=0.4504, p-value=0.0086\n",
      "    Ta: slope=0.0810, p-value=0.0048\n",
      "    Td: slope=0.1008, p-value=0.0058\n",
      "    Ts: slope=0.0989, p-value=0.0058\n",
      "    rain: slope=-0.0002, p-value=0.9225\n",
      "    sm1: slope=-0.0001, p-value=0.9741\n",
      "✓ HOLAPS trend plot saved for DE-Gri\n",
      "Processing DE-Hai...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=-0.0003, p-value=0.9741\n",
      "    H: slope=0.1391, p-value=0.2843\n",
      "    LE: slope=0.2611, p-value=0.0002\n",
      "    Rn: slope=0.4093, p-value=0.0026\n",
      "    Ta: slope=0.0707, p-value=0.0058\n",
      "    Td: slope=0.0816, p-value=0.0125\n",
      "    Ts: slope=0.0786, p-value=0.0086\n",
      "    rain: slope=0.0014, p-value=0.1119\n",
      "    sm1: slope=0.0005, p-value=0.2843\n",
      "✓ HOLAPS trend plot saved for DE-Hai\n",
      "Processing DE-HoH...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=0.0006, p-value=0.9225\n",
      "    H: slope=0.0430, p-value=0.4957\n",
      "    LE: slope=0.3462, p-value=0.0021\n",
      "    Rn: slope=0.4364, p-value=0.0071\n",
      "    Ta: slope=0.0744, p-value=0.0086\n",
      "    Td: slope=0.0795, p-value=0.0104\n",
      "    Ts: slope=0.0794, p-value=0.0104\n",
      "    rain: slope=0.0014, p-value=0.2561\n",
      "    sm1: slope=0.0006, p-value=0.4957\n",
      "✓ HOLAPS trend plot saved for DE-HoH\n",
      "Processing DE-Hzd...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=0.0017, p-value=0.6732\n",
      "    H: slope=0.1707, p-value=0.1443\n",
      "    LE: slope=0.2316, p-value=0.0104\n",
      "    Rn: slope=0.4393, p-value=0.0071\n",
      "    Ta: slope=0.0859, p-value=0.0032\n",
      "    Td: slope=0.0978, p-value=0.0071\n",
      "    Ts: slope=0.0963, p-value=0.0071\n",
      "    rain: slope=-0.0001, p-value=0.9741\n",
      "    sm1: slope=0.0000, p-value=0.9225\n",
      "✓ HOLAPS trend plot saved for DE-Hzd\n",
      "Processing DE-Kli...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=0.0025, p-value=0.6732\n",
      "    H: slope=0.1504, p-value=0.1119\n",
      "    LE: slope=0.2185, p-value=0.0058\n",
      "    Rn: slope=0.3770, p-value=0.0086\n",
      "    Ta: slope=0.0812, p-value=0.0039\n",
      "    Td: slope=0.0889, p-value=0.0086\n",
      "    Ts: slope=0.0892, p-value=0.0104\n",
      "    rain: slope=-0.0002, p-value=0.9225\n",
      "    sm1: slope=0.0000, p-value=0.9741\n",
      "✓ HOLAPS trend plot saved for DE-Kli\n",
      "Processing DE-Lnf...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=0.0010, p-value=0.9225\n",
      "    H: slope=0.0326, p-value=0.7212\n",
      "    LE: slope=0.4231, p-value=0.0002\n",
      "    Rn: slope=0.4742, p-value=0.0010\n",
      "    Ta: slope=0.0697, p-value=0.0086\n",
      "    Td: slope=0.0759, p-value=0.0212\n",
      "    Ts: slope=0.0732, p-value=0.0179\n",
      "    rain: slope=0.0022, p-value=0.0252\n",
      "    sm1: slope=0.0012, p-value=0.1119\n",
      "✓ HOLAPS trend plot saved for DE-Lnf\n",
      "Processing DE-Obe...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=0.0011, p-value=0.8203\n",
      "    H: slope=0.1784, p-value=0.2561\n",
      "    LE: slope=0.1432, p-value=0.0125\n",
      "    Rn: slope=0.2986, p-value=0.0150\n",
      "    Ta: slope=0.0782, p-value=0.0058\n",
      "    Td: slope=0.0855, p-value=0.0086\n",
      "    Ts: slope=0.0848, p-value=0.0086\n",
      "    rain: slope=-0.0002, p-value=0.9741\n",
      "    sm1: slope=-0.0002, p-value=0.5376\n",
      "✓ HOLAPS trend plot saved for DE-Obe\n",
      "Processing DE-RuR...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=-0.0025, p-value=0.4957\n",
      "    H: slope=0.0278, p-value=0.5813\n",
      "    LE: slope=0.1434, p-value=0.1443\n",
      "    Rn: slope=0.2488, p-value=0.1273\n",
      "    Ta: slope=0.0563, p-value=0.0125\n",
      "    Td: slope=0.0744, p-value=0.0212\n",
      "    Ts: slope=0.0711, p-value=0.0212\n",
      "    rain: slope=0.0011, p-value=0.1834\n",
      "    sm1: slope=-0.0005, p-value=0.4957\n",
      "✓ HOLAPS trend plot saved for DE-RuR\n",
      "Processing DE-RuS...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=-0.0031, p-value=0.7212\n",
      "    H: slope=0.0047, p-value=0.9741\n",
      "    LE: slope=0.1825, p-value=0.1273\n",
      "    Rn: slope=0.1954, p-value=0.1834\n",
      "    Ta: slope=0.0603, p-value=0.0150\n",
      "    Td: slope=0.0667, p-value=0.0350\n",
      "    Ts: slope=0.0681, p-value=0.0350\n",
      "    rain: slope=0.0032, p-value=0.0252\n",
      "    sm1: slope=0.0002, p-value=0.7703\n",
      "✓ HOLAPS trend plot saved for DE-RuS\n",
      "Processing DE-Tha...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=0.0014, p-value=0.6265\n",
      "    H: slope=0.2011, p-value=0.1273\n",
      "    LE: slope=0.1714, p-value=0.0026\n",
      "    Rn: slope=0.4133, p-value=0.0086\n",
      "    Ta: slope=0.0810, p-value=0.0048\n",
      "    Td: slope=0.0978, p-value=0.0058\n",
      "    Ts: slope=0.0948, p-value=0.0058\n",
      "    rain: slope=-0.0002, p-value=0.9225\n",
      "    sm1: slope=-0.0001, p-value=0.9225\n",
      "✓ HOLAPS trend plot saved for DE-Tha\n",
      "Processing DK-Sor...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=0.0024, p-value=0.7212\n",
      "    H: slope=0.1575, p-value=0.0556\n",
      "    LE: slope=0.0927, p-value=0.3810\n",
      "    Rn: slope=0.2615, p-value=0.1119\n",
      "    Ta: slope=0.0606, p-value=0.0252\n",
      "    Td: slope=0.0637, p-value=0.0150\n",
      "    Ts: slope=0.0634, p-value=0.0179\n",
      "    rain: slope=0.0001, p-value=0.9225\n",
      "    sm1: slope=-0.0001, p-value=0.8203\n",
      "✓ HOLAPS trend plot saved for DK-Sor\n",
      "Processing ES-Agu...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=-0.0009, p-value=0.7212\n",
      "    H: slope=-0.0576, p-value=0.8711\n",
      "    LE: slope=0.1291, p-value=0.6265\n",
      "    Rn: slope=0.1073, p-value=0.1273\n",
      "    Ta: slope=0.0404, p-value=0.0086\n",
      "    Td: slope=0.0445, p-value=0.0350\n",
      "    Ts: slope=0.0459, p-value=0.0297\n",
      "    rain: slope=0.0006, p-value=0.2843\n",
      "    sm1: slope=-0.0003, p-value=0.7703\n",
      "✓ HOLAPS trend plot saved for ES-Agu\n",
      "Processing ES-LJu...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=-0.0047, p-value=0.2843\n",
      "    H: slope=0.8314, p-value=0.0058\n",
      "    LE: slope=-1.1563, p-value=0.0058\n",
      "    Rn: slope=-0.3178, p-value=0.0855\n",
      "    Ta: slope=0.0491, p-value=0.0212\n",
      "    Td: slope=0.1028, p-value=0.0297\n",
      "    Ts: slope=0.1029, p-value=0.0297\n",
      "    rain: slope=-0.0014, p-value=0.0297\n",
      "    sm1: slope=-0.0031, p-value=0.0008\n",
      "✓ HOLAPS trend plot saved for ES-LJu\n",
      "No yearly trend file found for FI-Hyy\n",
      "No yearly trend file found for FI-Let\n",
      "Processing FR-Aur...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=-0.0027, p-value=0.5376\n",
      "    H: slope=-0.3167, p-value=0.0032\n",
      "    LE: slope=0.7004, p-value=0.0026\n",
      "    Rn: slope=0.3936, p-value=0.0058\n",
      "    Ta: slope=0.0640, p-value=0.0297\n",
      "    Td: slope=0.0396, p-value=0.3810\n",
      "    Ts: slope=0.0407, p-value=0.3810\n",
      "    rain: slope=0.0034, p-value=0.0071\n",
      "    sm1: slope=0.0022, p-value=0.0104\n",
      "✓ HOLAPS trend plot saved for FR-Aur\n",
      "Processing FR-Bil...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=0.0024, p-value=0.7703\n",
      "    H: slope=0.0606, p-value=0.3810\n",
      "    LE: slope=0.0101, p-value=0.9741\n",
      "    Rn: slope=0.0539, p-value=0.6732\n",
      "    Ta: slope=0.0453, p-value=0.0556\n",
      "    Td: slope=0.0499, p-value=0.0556\n",
      "    Ts: slope=0.0481, p-value=0.0744\n",
      "    rain: slope=0.0001, p-value=1.0000\n",
      "    sm1: slope=-0.0000, p-value=1.0000\n",
      "✓ HOLAPS trend plot saved for FR-Bil\n",
      "Processing FR-Gri...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=-0.0021, p-value=0.8711\n",
      "    H: slope=0.0012, p-value=1.0000\n",
      "    LE: slope=0.2751, p-value=0.0179\n",
      "    Rn: slope=0.2324, p-value=0.1443\n",
      "    Ta: slope=0.0517, p-value=0.0297\n",
      "    Td: slope=0.0466, p-value=0.1273\n",
      "    Ts: slope=0.0465, p-value=0.0980\n",
      "    rain: slope=0.0019, p-value=0.1834\n",
      "    sm1: slope=0.0003, p-value=0.6732\n",
      "✓ HOLAPS trend plot saved for FR-Gri\n",
      "Processing FR-Hes...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=-0.0017, p-value=0.6732\n",
      "    H: slope=0.0179, p-value=1.0000\n",
      "    LE: slope=0.3321, p-value=0.0104\n",
      "    Rn: slope=0.3410, p-value=0.0644\n",
      "    Ta: slope=0.0721, p-value=0.0179\n",
      "    Td: slope=0.0712, p-value=0.0410\n",
      "    Ts: slope=0.0766, p-value=0.0478\n",
      "    rain: slope=0.0016, p-value=0.0125\n",
      "    sm1: slope=0.0002, p-value=0.7703\n",
      "✓ HOLAPS trend plot saved for FR-Hes\n",
      "Processing FR-Lam...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=-0.0034, p-value=0.5813\n",
      "    H: slope=-0.3784, p-value=0.0013\n",
      "    LE: slope=0.6728, p-value=0.0039\n",
      "    Rn: slope=0.3820, p-value=0.0150\n",
      "    Ta: slope=0.0598, p-value=0.0478\n",
      "    Td: slope=0.0318, p-value=0.3810\n",
      "    Ts: slope=0.0320, p-value=0.4173\n",
      "    rain: slope=0.0042, p-value=0.0010\n",
      "    sm1: slope=0.0027, p-value=0.0048\n",
      "✓ HOLAPS trend plot saved for FR-Lam\n",
      "Processing FR-LBr...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=0.0016, p-value=0.8711\n",
      "    H: slope=0.1284, p-value=0.2843\n",
      "    LE: slope=0.1183, p-value=0.0644\n",
      "    Rn: slope=0.2139, p-value=0.0980\n",
      "    Ta: slope=0.0460, p-value=0.0297\n",
      "    Td: slope=0.0540, p-value=0.0252\n",
      "    Ts: slope=0.0550, p-value=0.0252\n",
      "    rain: slope=0.0017, p-value=0.2058\n",
      "    sm1: slope=0.0000, p-value=0.8203\n",
      "✓ HOLAPS trend plot saved for FR-LBr\n",
      "Processing IT-BCi...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=0.0019, p-value=0.9225\n",
      "    H: slope=-0.1800, p-value=0.3145\n",
      "    LE: slope=0.2742, p-value=0.1630\n",
      "    Rn: slope=0.1307, p-value=0.2561\n",
      "    Ta: slope=0.0394, p-value=0.0004\n",
      "    Td: slope=0.0267, p-value=0.1630\n",
      "    Ts: slope=0.0260, p-value=0.1443\n",
      "    rain: slope=-0.0007, p-value=0.7212\n",
      "    sm1: slope=0.0002, p-value=0.8203\n",
      "✓ HOLAPS trend plot saved for IT-BCi\n",
      "Processing IT-Col...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=0.0002, p-value=0.8203\n",
      "    H: slope=-0.2051, p-value=0.1630\n",
      "    LE: slope=0.3524, p-value=0.0001\n",
      "    Rn: slope=0.1992, p-value=0.2561\n",
      "    Ta: slope=0.0531, p-value=0.0032\n",
      "    Td: slope=0.0304, p-value=0.0744\n",
      "    Ts: slope=0.0294, p-value=0.0744\n",
      "    rain: slope=0.0023, p-value=0.0855\n",
      "    sm1: slope=0.0019, p-value=0.0150\n",
      "✓ HOLAPS trend plot saved for IT-Col\n",
      "Processing IT-Cp2...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2019 (19)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=0.0007, p-value=0.3630\n",
      "    H: slope=-0.2971, p-value=0.1417\n",
      "    LE: slope=0.7289, p-value=0.0118\n",
      "    Rn: slope=0.4304, p-value=0.0002\n",
      "    Ta: slope=0.0000, p-value=1.0000\n",
      "    Td: slope=-0.0395, p-value=0.1617\n",
      "    Ts: slope=-0.0398, p-value=0.1417\n",
      "    rain: slope=0.0033, p-value=0.0802\n",
      "    sm1: slope=0.0018, p-value=0.0501\n",
      "✓ HOLAPS trend plot saved for IT-Cp2\n",
      "Processing IT-Cpz...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2019 (19)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=0.0007, p-value=0.3630\n",
      "    H: slope=-0.2971, p-value=0.1417\n",
      "    LE: slope=0.7289, p-value=0.0118\n",
      "    Rn: slope=0.4304, p-value=0.0002\n",
      "    Ta: slope=0.0000, p-value=1.0000\n",
      "    Td: slope=-0.0395, p-value=0.1617\n",
      "    Ts: slope=-0.0398, p-value=0.1417\n",
      "    rain: slope=0.0033, p-value=0.0802\n",
      "    sm1: slope=0.0018, p-value=0.0501\n",
      "✓ HOLAPS trend plot saved for IT-Cpz\n",
      "Processing IT-Lav...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=-0.0023, p-value=0.7212\n",
      "    H: slope=-0.1136, p-value=0.1630\n",
      "    LE: slope=0.1376, p-value=0.0212\n",
      "    Rn: slope=0.0341, p-value=0.8203\n",
      "    Ta: slope=0.0755, p-value=0.0002\n",
      "    Td: slope=0.0737, p-value=0.0048\n",
      "    Ts: slope=0.0726, p-value=0.0048\n",
      "    rain: slope=0.0025, p-value=0.0744\n",
      "    sm1: slope=0.0006, p-value=0.0478\n",
      "✓ HOLAPS trend plot saved for IT-Lav\n",
      "Processing IT-MBo...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=-0.0031, p-value=0.5376\n",
      "    H: slope=-0.0937, p-value=0.0980\n",
      "    LE: slope=0.1560, p-value=0.0212\n",
      "    Rn: slope=0.0613, p-value=0.6732\n",
      "    Ta: slope=0.0767, p-value=0.0007\n",
      "    Td: slope=0.0720, p-value=0.0048\n",
      "    Ts: slope=0.0696, p-value=0.0048\n",
      "    rain: slope=0.0017, p-value=0.2561\n",
      "    sm1: slope=0.0007, p-value=0.0350\n",
      "✓ HOLAPS trend plot saved for IT-MBo\n",
      "Processing IT-Ren...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=-0.0020, p-value=0.5813\n",
      "    H: slope=-0.1725, p-value=0.0212\n",
      "    LE: slope=0.1312, p-value=0.0744\n",
      "    Rn: slope=-0.0379, p-value=0.7212\n",
      "    Ta: slope=0.0791, p-value=0.0021\n",
      "    Td: slope=0.0503, p-value=0.0478\n",
      "    Ts: slope=0.0506, p-value=0.0556\n",
      "    rain: slope=0.0011, p-value=0.2300\n",
      "    sm1: slope=0.0009, p-value=0.0556\n",
      "✓ HOLAPS trend plot saved for IT-Ren\n",
      "Processing IT-Ro2...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=0.0025, p-value=0.5376\n",
      "    H: slope=-0.3497, p-value=0.0410\n",
      "    LE: slope=0.5640, p-value=0.0071\n",
      "    Rn: slope=0.2303, p-value=0.0212\n",
      "    Ta: slope=0.0519, p-value=0.0007\n",
      "    Td: slope=0.0309, p-value=0.0980\n",
      "    Ts: slope=0.0308, p-value=0.1119\n",
      "    rain: slope=0.0032, p-value=0.1443\n",
      "    sm1: slope=0.0018, p-value=0.0125\n",
      "✓ HOLAPS trend plot saved for IT-Ro2\n",
      "Processing IT-SR2...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2019 (19)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=0.0004, p-value=0.4841\n",
      "    H: slope=-0.2024, p-value=0.2629\n",
      "    LE: slope=0.6756, p-value=0.0096\n",
      "    Rn: slope=0.4345, p-value=0.0033\n",
      "    Ta: slope=0.0000, p-value=1.0000\n",
      "    Td: slope=-0.0224, p-value=0.2629\n",
      "    Ts: slope=-0.0224, p-value=0.2629\n",
      "    rain: slope=0.0037, p-value=0.0252\n",
      "    sm1: slope=0.0016, p-value=0.2079\n",
      "✓ HOLAPS trend plot saved for IT-SR2\n",
      "Processing IT-SRo...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2019 (19)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=0.0004, p-value=0.4841\n",
      "    H: slope=-0.2024, p-value=0.2629\n",
      "    LE: slope=0.6756, p-value=0.0096\n",
      "    Rn: slope=0.4345, p-value=0.0033\n",
      "    Ta: slope=0.0000, p-value=1.0000\n",
      "    Td: slope=-0.0224, p-value=0.2629\n",
      "    Ts: slope=-0.0224, p-value=0.2629\n",
      "    rain: slope=0.0037, p-value=0.0252\n",
      "    sm1: slope=0.0016, p-value=0.2079\n",
      "✓ HOLAPS trend plot saved for IT-SRo\n",
      "Processing IT-Tor...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=-0.0010, p-value=0.7703\n",
      "    H: slope=0.1568, p-value=0.2300\n",
      "    LE: slope=-0.4020, p-value=0.0058\n",
      "    Rn: slope=-0.1981, p-value=0.1630\n",
      "    Ta: slope=0.0687, p-value=0.0021\n",
      "    Td: slope=0.1324, p-value=0.0058\n",
      "    Ts: slope=0.1351, p-value=0.0048\n",
      "    rain: slope=-0.0016, p-value=0.0556\n",
      "    sm1: slope=-0.0014, p-value=0.0297\n",
      "✓ HOLAPS trend plot saved for IT-Tor\n",
      "Processing IT-TrF...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=0.0014, p-value=0.8203\n",
      "    H: slope=0.1595, p-value=0.0179\n",
      "    LE: slope=-0.4212, p-value=0.0179\n",
      "    Rn: slope=-0.1836, p-value=0.2843\n",
      "    Ta: slope=0.0619, p-value=0.0058\n",
      "    Td: slope=0.1180, p-value=0.0039\n",
      "    Ts: slope=0.1166, p-value=0.0032\n",
      "    rain: slope=-0.0016, p-value=0.0556\n",
      "    sm1: slope=-0.0020, p-value=0.0252\n",
      "✓ HOLAPS trend plot saved for IT-TrF\n",
      "Processing NL-Loo...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=-0.0013, p-value=0.9225\n",
      "    H: slope=0.0313, p-value=0.8711\n",
      "    LE: slope=0.0354, p-value=0.3145\n",
      "    Rn: slope=0.0646, p-value=0.7212\n",
      "    Ta: slope=0.0488, p-value=0.0297\n",
      "    Td: slope=0.0527, p-value=0.0252\n",
      "    Ts: slope=0.0528, p-value=0.0297\n",
      "    rain: slope=0.0004, p-value=0.6732\n",
      "    sm1: slope=-0.0000, p-value=0.8203\n",
      "✓ HOLAPS trend plot saved for NL-Loo\n",
      "No yearly trend file found for plots\n",
      "Processing RU-Fyo...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=0.0050, p-value=0.4555\n",
      "    H: slope=-0.0807, p-value=0.4173\n",
      "    LE: slope=0.2205, p-value=0.0000\n",
      "    Rn: slope=0.1111, p-value=0.2300\n",
      "    Ta: slope=0.0727, p-value=0.0032\n",
      "    Td: slope=0.0744, p-value=0.0179\n",
      "    Ts: slope=0.0725, p-value=0.0125\n",
      "    rain: slope=0.0013, p-value=0.0556\n",
      "    sm1: slope=0.0011, p-value=0.0104\n",
      "✓ HOLAPS trend plot saved for RU-Fyo\n",
      "Processing SE-Htm...\n",
      "  P-values shape: (1, 15)\n",
      "  Slopes shape: (1, 15)\n",
      "  P-values columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Slopes columns: ['Analysis', 'Period', 'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', 'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5']\n",
      "  Periods: ['2001-2020 (20)']\n",
      "  Analyses: ['Complete Period']\n",
      "    GHF: slope=-0.0006, p-value=0.9225\n",
      "    H: slope=0.0912, p-value=0.5376\n",
      "    LE: slope=0.0659, p-value=0.2843\n",
      "    Rn: slope=0.1190, p-value=0.4957\n",
      "    Ta: slope=0.0777, p-value=0.0086\n",
      "    Td: slope=0.0738, p-value=0.0104\n",
      "    Ts: slope=0.0738, p-value=0.0179\n",
      "    rain: slope=0.0007, p-value=0.2561\n",
      "    sm1: slope=0.0002, p-value=0.4173\n",
      "✓ HOLAPS trend plot saved for SE-Htm\n",
      "No yearly trend file found for SE-Nor\n",
      "All station directories processed!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# Define HOLAPS parameters and assign fixed colors\n",
    "color_dict = {\n",
    "    'GHF': '#1f77b4',          # blue\n",
    "    'H': '#ff7f0e',            # orange\n",
    "    'LE': '#2ca02c',           # green\n",
    "    'Rn': '#d62728',           # red\n",
    "    'Ta': '#9467bd',           # purple\n",
    "    'Td': '#8c564b',           # brown\n",
    "    'Ts': '#e377c2',           # pink\n",
    "    'rain': '#17becf',         # teal\n",
    "    'sm1': '#bcbd22'           # olive\n",
    "}\n",
    "\n",
    "parameters = list(color_dict.keys())\n",
    "\n",
    "# Fixed absolute Y positions for each parameter\n",
    "parameter_distances = {\n",
    "    'GHF': 0.2,\n",
    "    'H': 0.4,\n",
    "    'LE': 0.6,\n",
    "    'Rn': 0.8,\n",
    "    'Ta': 1.0,\n",
    "    'Td': 1.2,\n",
    "    'Ts': 1.4,\n",
    "    'rain': 1.6,\n",
    "    'sm1': 1.8\n",
    "}\n",
    "\n",
    "# Directory containing station subdirectories\n",
    "input_directory = r'C:\\Deepak\\HOLAPS\\monthly\\station_data2'\n",
    "output_directory = r'C:\\Deepak\\HOLAPS\\monthly\\station_data2\\plots'\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Get list of all station subdirectories\n",
    "station_dirs = [d for d in os.listdir(input_directory) \n",
    "                if os.path.isdir(os.path.join(input_directory, d))]\n",
    "\n",
    "print(f\"Found {len(station_dirs)} station directories\")\n",
    "\n",
    "# Process each station directory\n",
    "for station_dir in station_dirs:\n",
    "    try:\n",
    "        station_path = os.path.join(input_directory, station_dir)\n",
    "        \n",
    "        # Look for yearly trend file in this station directory\n",
    "        trend_files = [f for f in os.listdir(station_path) \n",
    "                      if f.endswith('_yearly.xlsx') and 'trend' in f.lower()]\n",
    "        \n",
    "        if not trend_files:\n",
    "            print(f\"No yearly trend file found for {station_dir}\")\n",
    "            continue\n",
    "            \n",
    "        trend_file = trend_files[0]\n",
    "        station_name = station_dir  # Use directory name as station name\n",
    "        \n",
    "        print(f\"Processing {station_name}...\")\n",
    "        \n",
    "        # Create figure\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(20, 12))\n",
    "        \n",
    "        # File path\n",
    "        file_path = os.path.join(station_path, trend_file)\n",
    "        \n",
    "        # Read the Excel file\n",
    "        p_values_df = pd.read_excel(file_path, sheet_name='P-values')\n",
    "        slopes_df = pd.read_excel(file_path, sheet_name='Slopes')\n",
    "        \n",
    "        print(f\"  P-values shape: {p_values_df.shape}\")\n",
    "        print(f\"  Slopes shape: {slopes_df.shape}\")\n",
    "        print(f\"  P-values columns: {list(p_values_df.columns)}\")\n",
    "        print(f\"  Slopes columns: {list(slopes_df.columns)}\")\n",
    "        \n",
    "        # Clean the data\n",
    "        p_values_df = p_values_df.dropna(how='all')\n",
    "        slopes_df = slopes_df.dropna(how='all')\n",
    "        p_values_df = p_values_df.reset_index(drop=True)\n",
    "        slopes_df = slopes_df.reset_index(drop=True)\n",
    "        \n",
    "        # Get periods and analyses\n",
    "        periods = slopes_df['Period'].values\n",
    "        analyses = slopes_df['Analysis'].values\n",
    "        \n",
    "        print(f\"  Periods: {periods}\")\n",
    "        print(f\"  Analyses: {analyses}\")\n",
    "        \n",
    "        # Plot data for each period/analysis\n",
    "        for period_idx, (period, analysis) in enumerate(zip(periods, analyses)):\n",
    "            for param in parameters:\n",
    "                if param not in slopes_df.columns or param not in p_values_df.columns:\n",
    "                    continue\n",
    "                    \n",
    "                slope = slopes_df[param].iloc[period_idx]\n",
    "                p_val = p_values_df[param].iloc[period_idx]\n",
    "\n",
    "                if pd.isna(p_val) or pd.isna(slope):\n",
    "                    continue\n",
    "\n",
    "                print(f\"    {param}: slope={slope:.4f}, p-value={p_val:.4f}\")\n",
    "\n",
    "                # FIXED POSITION: Use the predefined distance from zero\n",
    "                base_distance = parameter_distances[param]\n",
    "                y_position = base_distance if slope >= 0 else -base_distance\n",
    "                \n",
    "                x_position = period_idx  # Center on the period position\n",
    "                \n",
    "                # Small random offset to avoid perfect alignment\n",
    "                x_offset = np.random.uniform(-0.15, 0.15)\n",
    "                x_position += x_offset\n",
    "\n",
    "                # Marker rules based on p-values\n",
    "                if p_val < 0.1:\n",
    "                    marker = 'o'   # full circle\n",
    "                    marker_size = 300\n",
    "                    fill_style = 'full'\n",
    "                    edge_width = 4.0\n",
    "                    alpha_val = 1.0\n",
    "                elif p_val < 0.2:\n",
    "                    marker = '^'   # triangle\n",
    "                    marker_size = 260\n",
    "                    fill_style = 'full'\n",
    "                    edge_width = 4.0\n",
    "                    alpha_val = 0.9\n",
    "                else:\n",
    "                    marker = 'o'   # open circle\n",
    "                    marker_size = 220\n",
    "                    fill_style = 'none'\n",
    "                    edge_width = 3.5\n",
    "                    alpha_val = 0.8\n",
    "\n",
    "                # Plot marker\n",
    "                ax.scatter(x_position, y_position, s=marker_size,\n",
    "                           c=color_dict[param] if fill_style == 'full' else 'none',\n",
    "                           marker=marker, edgecolors=color_dict[param],\n",
    "                           linewidths=edge_width, alpha=alpha_val, zorder=5)\n",
    "        \n",
    "        # Customize plot\n",
    "        ax.set_xlabel('Analysis Periods', fontsize=20, fontweight='bold')\n",
    "        ax.set_xticks(range(len(periods)))\n",
    "        \n",
    "        # Create labels showing both analysis type and period\n",
    "        x_labels = [f\"{analyses[i]}\\n({periods[i]})\" for i in range(len(periods))]\n",
    "        ax.set_xticklabels(x_labels, rotation=45, ha='right', fontsize=16)\n",
    "        \n",
    "        # Set y-axis limits based on maximum distance\n",
    "        max_distance = max(parameter_distances.values())\n",
    "        y_limit = max_distance * 1.2  # Add some padding\n",
    "        ax.set_ylim(-y_limit, y_limit)\n",
    "        \n",
    "        # Remove y-axis labels and ticks\n",
    "        ax.set_yticks([])\n",
    "        ax.set_ylabel('')\n",
    "        \n",
    "        # Zero line\n",
    "        ax.axhline(y=0, color='black', linestyle='-', alpha=0.8, linewidth=3, zorder=1)\n",
    "        \n",
    "        # Customize spines\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['left'].set_visible(False)\n",
    "\n",
    "        # Add vertical lines to separate analysis groups\n",
    "        for i in range(len(periods) + 1):\n",
    "            ax.axvline(x=i - 0.5, color='gray', linestyle='--', alpha=0.5, linewidth=2, zorder=1)\n",
    "\n",
    "        # Add grid for better readability\n",
    "        ax.grid(True, axis='y', linestyle='--', alpha=0.4, linewidth=1.2, zorder=1)\n",
    "\n",
    "        # Main title\n",
    "        plt.title(f'HOLAPS Trend Analysis for {station_name}',\n",
    "                 fontsize=22, fontweight='bold', pad=20)\n",
    "\n",
    "        # Create legends\n",
    "        legend_elements = [\n",
    "            Line2D([0], [0], marker='s', color='w',\n",
    "                   markerfacecolor=color_dict[param],\n",
    "                   markersize=16, label=param)\n",
    "            for param in parameters\n",
    "        ]\n",
    "\n",
    "        marker_elements = [\n",
    "            Line2D([0], [0], marker='o', color='black', markerfacecolor='black',\n",
    "                   markersize=20, linestyle='None', label='p < 0.1 (Full circle)'),\n",
    "            Line2D([0], [0], marker='^', color='black', markerfacecolor='black',\n",
    "                   markersize=20, linestyle='None', label='0.1 ≤ p < 0.2 (Triangle)'),\n",
    "            Line2D([0], [0], marker='o', color='black', markerfacecolor='none',\n",
    "                   markersize=20, linestyle='None', label='p ≥ 0.2 (Open circle)')\n",
    "        ]\n",
    "\n",
    "        # Place legends\n",
    "        legend1 = ax.legend(handles=legend_elements, \n",
    "                          loc='upper left',\n",
    "                          bbox_to_anchor=(1.02, 1),\n",
    "                          fontsize=14,\n",
    "                          title='HOLAPS Parameters', \n",
    "                          title_fontsize=16)\n",
    "\n",
    "        legend2 = ax.legend(handles=marker_elements, \n",
    "                          loc='upper left',\n",
    "                          bbox_to_anchor=(1.02, 0.7),\n",
    "                          fontsize=14,\n",
    "                          title='Significance Levels', \n",
    "                          title_fontsize=16)\n",
    "\n",
    "        # Add both legends to the plot\n",
    "        ax.add_artist(legend1)\n",
    "        \n",
    "        # Adjust layout for larger elements\n",
    "        plt.tight_layout(rect=[0, 0, 0.82, 0.95])\n",
    "        \n",
    "        # Save the plot with high DPI\n",
    "        output_path = os.path.join(output_directory, f\"{station_name}_holaps_trend_plot.png\")\n",
    "        plt.savefig(output_path, dpi=350, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"✓ HOLAPS trend plot saved for {station_name}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {station_dir}: {str(e)}\")\n",
    "        import traceback\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "print(\"All station directories processed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f1ee0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 44 station directories\n",
      "Created 5 groups of stations\n",
      "\n",
      "Processing group 1: ['AT-Neu', 'BE-Bra', 'BE-Lon', 'BE-Vie', 'CH-Cha', 'CH-Dav', 'CH-Fru', 'CZ-BK1', 'CZ-wet', 'DE-Geb']\n",
      "  Processing AT-Neu...\n",
      "  Processing BE-Bra...\n",
      "  Processing BE-Lon...\n",
      "  Processing BE-Vie...\n",
      "  Processing CH-Cha...\n",
      "  Processing CH-Dav...\n",
      "  Processing CH-Fru...\n",
      "  Processing CZ-BK1...\n",
      "  Processing CZ-wet...\n",
      "  Processing DE-Geb...\n",
      "✓ Group 1 plot saved with 10 stations\n",
      "\n",
      "Processing group 2: ['DE-Gri', 'DE-Hai', 'DE-HoH', 'DE-Hzd', 'DE-Kli', 'DE-Lnf', 'DE-Obe', 'DE-RuR', 'DE-RuS', 'DE-Tha']\n",
      "  Processing DE-Gri...\n",
      "  Processing DE-Hai...\n",
      "  Processing DE-HoH...\n",
      "  Processing DE-Hzd...\n",
      "  Processing DE-Kli...\n",
      "  Processing DE-Lnf...\n",
      "  Processing DE-Obe...\n",
      "  Processing DE-RuR...\n",
      "  Processing DE-RuS...\n",
      "  Processing DE-Tha...\n",
      "✓ Group 2 plot saved with 10 stations\n",
      "\n",
      "Processing group 3: ['DK-Sor', 'ES-Agu', 'ES-LJu', 'FR-Aur', 'FR-Bil', 'FR-Gri', 'FR-Hes', 'FR-Lam', 'FR-LBr', 'IT-BCi']\n",
      "  Processing DK-Sor...\n",
      "  Processing ES-Agu...\n",
      "  Processing ES-LJu...\n",
      "  Processing FR-Aur...\n",
      "  Processing FR-Bil...\n",
      "  Processing FR-Gri...\n",
      "  Processing FR-Hes...\n",
      "  Processing FR-Lam...\n",
      "  Processing FR-LBr...\n",
      "  Processing IT-BCi...\n",
      "✓ Group 3 plot saved with 10 stations\n",
      "\n",
      "Processing group 4: ['IT-Col', 'IT-Cp2', 'IT-Cpz', 'IT-Lav', 'IT-MBo', 'IT-Ren', 'IT-Ro2', 'IT-SR2', 'IT-SRo', 'IT-Tor']\n",
      "  Processing IT-Col...\n",
      "  Processing IT-Cp2...\n",
      "  Processing IT-Cpz...\n",
      "  Processing IT-Lav...\n",
      "  Processing IT-MBo...\n",
      "  Processing IT-Ren...\n",
      "  Processing IT-Ro2...\n",
      "  Processing IT-SR2...\n",
      "  Processing IT-SRo...\n",
      "  Processing IT-Tor...\n",
      "✓ Group 4 plot saved with 10 stations\n",
      "\n",
      "Processing group 5: ['IT-TrF', 'NL-Loo', 'RU-Fyo', 'SE-Htm']\n",
      "  Processing IT-TrF...\n",
      "  Processing NL-Loo...\n",
      "  Processing RU-Fyo...\n",
      "  Processing SE-Htm...\n",
      "✓ Group 5 plot saved with 4 stations\n",
      "All station groups processed!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# Define HOLAPS parameters and assign fixed colors\n",
    "color_dict = {\n",
    "    'GHF': '#1f77b4',          # blue\n",
    "    'H': '#ff7f0e',            # orange\n",
    "    'LE': '#2ca02c',           # green\n",
    "    'Rn': '#d62728',           # red\n",
    "    'Ta': '#9467bd',           # purple\n",
    "    'Td': '#8c564b',           # brown\n",
    "    'Ts': '#e377c2',           # pink\n",
    "    'rain': '#17becf',         # teal\n",
    "    'sm1': '#bcbd22',           # olive\n",
    "    'sm2': '#ff69b4',    # hot pink\n",
    "    'sm3': '#00ced1',    # dark turquoise\n",
    "    'sm4': '#ffa500',    # bright orange\n",
    "    'sm5': '#8a2be2'    # blue violet\n",
    "}\n",
    "\n",
    "parameters = list(color_dict.keys())\n",
    "\n",
    "# Fixed absolute Y positions for each parameter\n",
    "parameter_distances = {\n",
    "    'GHF': 0.2,\n",
    "    'H': 0.4,\n",
    "    'LE': 0.6,\n",
    "    'Rn': 0.8,\n",
    "    'Ta': 1.0,\n",
    "    'Td': 1.2,\n",
    "    'Ts': 1.4,\n",
    "    'rain': 1.6,\n",
    "    'sm1': 1.8,\n",
    "    'sm2': 2.0,\n",
    "    'sm3': 2.2,\n",
    "    'sm4': 2.4,\n",
    "    'sm5': 2.6\n",
    "}\n",
    "\n",
    "# Directory containing station subdirectories\n",
    "input_directory = r'C:\\Deepak\\HOLAPS\\monthly\\station_data2'\n",
    "output_directory = r'C:\\Deepak\\HOLAPS\\monthly\\station_data2\\plots4'\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Get list of all station subdirectories\n",
    "station_dirs = [d for d in os.listdir(input_directory)\n",
    "                if os.path.isdir(os.path.join(input_directory, d)) and not d.lower().startswith('plots') and not d.lower().startswith('yearly')]\n",
    "print(f\"Found {len(station_dirs)} station directories\")\n",
    "\n",
    "# Group stations - you can modify this to group as needed\n",
    "# Example: Group first 10 stations together\n",
    "station_groups = []\n",
    "group_size = 10\n",
    "\n",
    "for i in range(0, len(station_dirs), group_size):\n",
    "    station_groups.append(station_dirs[i:i + group_size])\n",
    "\n",
    "print(f\"Created {len(station_groups)} groups of stations\")\n",
    "\n",
    "# Process each group of stations\n",
    "for group_idx, station_group in enumerate(station_groups):\n",
    "    try:\n",
    "        print(f\"\\nProcessing group {group_idx + 1}: {station_group}\")\n",
    "        \n",
    "        # Create figure - wider for multiple stations\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(25, 12))\n",
    "        \n",
    "        all_station_data = []\n",
    "        \n",
    "        # Process each station in the group\n",
    "        for station_idx, station_dir in enumerate(station_group):\n",
    "            station_path = os.path.join(input_directory, station_dir)\n",
    "            \n",
    "            # Look for yearly trend file in this station directory\n",
    "            trend_files = [f for f in os.listdir(station_path) \n",
    "                          if f.endswith('_yearly.xlsx') and 'trend' in f.lower()]\n",
    "            \n",
    "            if not trend_files:\n",
    "                print(f\"  No yearly trend file found for {station_dir}\")\n",
    "                continue\n",
    "                \n",
    "            trend_file = trend_files[0]\n",
    "            station_name = station_dir\n",
    "            \n",
    "            print(f\"  Processing {station_name}...\")\n",
    "            \n",
    "            # File path\n",
    "            file_path = os.path.join(station_path, trend_file)\n",
    "            \n",
    "            # Read the Excel file\n",
    "            p_values_df = pd.read_excel(file_path, sheet_name='P-values')\n",
    "            slopes_df = pd.read_excel(file_path, sheet_name='Slopes')\n",
    "            \n",
    "            # Clean the data\n",
    "            p_values_df = p_values_df.dropna(how='all')\n",
    "            slopes_df = slopes_df.dropna(how='all')\n",
    "            p_values_df = p_values_df.reset_index(drop=True)\n",
    "            slopes_df = slopes_df.reset_index(drop=True)\n",
    "            \n",
    "            # Get periods and analyses (should be just one row for yearly data)\n",
    "            periods = slopes_df['Period'].values\n",
    "            analyses = slopes_df['Analysis'].values\n",
    "            \n",
    "            # For each parameter, plot for this station\n",
    "            for param in parameters:\n",
    "                if param not in slopes_df.columns or param not in p_values_df.columns:\n",
    "                    continue\n",
    "                    \n",
    "                slope = slopes_df[param].iloc[0]  # First (and only) row for yearly data\n",
    "                p_val = p_values_df[param].iloc[0]\n",
    "\n",
    "                if pd.isna(p_val) or pd.isna(slope):\n",
    "                    continue\n",
    "\n",
    "                # X position: station index (spaced out)\n",
    "                x_position = station_idx * 2  # Space stations 2 units apart\n",
    "                \n",
    "                # Y position: parameter position + small random offset\n",
    "                base_distance = parameter_distances[param]\n",
    "                y_position = base_distance if slope >= 0 else -base_distance\n",
    "                \n",
    "                # Small vertical offset to avoid perfect alignment\n",
    "                #y_offset = np.random.uniform(-0.05, 0.05)\n",
    "                #y_position += y_offset\n",
    "\n",
    "                # Marker rules based on p-values\n",
    "                if p_val < 0.1:\n",
    "                    marker = 'o'   # full circle\n",
    "                    marker_size = 250\n",
    "                    fill_style = 'full'\n",
    "                    edge_width = 3.0\n",
    "                    alpha_val = 1.0\n",
    "                elif p_val < 0.2:\n",
    "                    marker = '^'   # triangle\n",
    "                    marker_size = 220\n",
    "                    fill_style = 'full'\n",
    "                    edge_width = 3.0\n",
    "                    alpha_val = 0.9\n",
    "                else:\n",
    "                    marker = 'o'   # open circle\n",
    "                    marker_size = 200\n",
    "                    fill_style = 'none'\n",
    "                    edge_width = 2.5\n",
    "                    alpha_val = 0.8\n",
    "\n",
    "                # Plot marker\n",
    "                ax.scatter(x_position, y_position, s=marker_size,\n",
    "                           c=color_dict[param] if fill_style == 'full' else 'none',\n",
    "                           marker=marker, edgecolors=color_dict[param],\n",
    "                           linewidths=edge_width, alpha=alpha_val, zorder=5,\n",
    "                           label=f'{station_name}_{param}' if station_idx == 0 else \"\")\n",
    "        \n",
    "        # Customize plot\n",
    "        ax.set_xlabel('Stations', fontsize=20, fontweight='bold')\n",
    "        ax.set_xticks(range(0, len(station_group) * 2, 2))\n",
    "        ax.set_xticklabels(station_group, rotation=45, ha='right', fontsize=14)\n",
    "        \n",
    "        # Set y-axis limits based on maximum distance\n",
    "        max_distance = max(parameter_distances.values())\n",
    "        y_limit = max_distance * 1.3  # Add some padding\n",
    "        ax.set_ylim(-y_limit, y_limit)\n",
    "        \n",
    "        # Remove y-axis labels and ticks\n",
    "        ax.set_yticks([])\n",
    "        ax.set_ylabel('')\n",
    "        \n",
    "        # Zero line\n",
    "        ax.axhline(y=0, color='black', linestyle='-', alpha=0.8, linewidth=2, zorder=1)\n",
    "        \n",
    "        # Add vertical lines to separate stations\n",
    "        for i in range(len(station_group) + 1):\n",
    "            ax.axvline(x=i * 2 - 1, color='gray', linestyle='--', alpha=0.3, linewidth=1, zorder=1)\n",
    "\n",
    "        # Add grid for better readability\n",
    "        ax.grid(True, axis='y', linestyle='--', alpha=0.3, linewidth=1, zorder=1)\n",
    "\n",
    "        # Main title\n",
    "        plt.title(f'HOLAPS Yearly  Trend Analysis - Stations {group_idx * group_size + 1} to {group_idx * group_size + len(station_group)}',\n",
    "                 fontsize=22, fontweight='bold', pad=20)\n",
    "\n",
    "        # Customize spines\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['left'].set_visible(False)\n",
    "\n",
    "        # Create legends\n",
    "        legend_elements = [\n",
    "            Line2D([0], [0], marker='s', color='w',\n",
    "                   markerfacecolor=color_dict[param],\n",
    "                   markersize=12, label=param)\n",
    "            for param in parameters\n",
    "        ]\n",
    "\n",
    "        marker_elements = [\n",
    "            Line2D([0], [0], marker='o', color='black', markerfacecolor='black',\n",
    "                   markersize=15, linestyle='None', label='p < 0.1 (Full circle)'),\n",
    "            Line2D([0], [0], marker='^', color='black', markerfacecolor='black',\n",
    "                   markersize=15, linestyle='None', label='0.1 ≤ p < 0.2 (Triangle)'),\n",
    "            Line2D([0], [0], marker='o', color='black', markerfacecolor='none',\n",
    "                   markersize=15, linestyle='None', label='p ≥ 0.2 (Open circle)')\n",
    "        ]\n",
    "\n",
    "        # Place legends\n",
    "        legend1 = ax.legend(handles=legend_elements, \n",
    "                          loc='upper left',\n",
    "                          bbox_to_anchor=(1.02, 1),\n",
    "                          fontsize=12,\n",
    "                          title='HOLAPS Parameters', \n",
    "                          title_fontsize=14)\n",
    "        \n",
    "        ax.add_artist(legend1)\n",
    "\n",
    "        legend2 = ax.legend(handles=marker_elements, \n",
    "                          loc='lower left',\n",
    "                          bbox_to_anchor=(1.02, 0.35),\n",
    "                          fontsize=12,\n",
    "                          title='Significance Levels', \n",
    "                          title_fontsize=14)\n",
    "\n",
    "        # Add both legends to the plot\n",
    "       \n",
    "        \n",
    "        # Adjust layout for larger elements\n",
    "        plt.tight_layout(rect=[0, 0, 0.85, 0.95])\n",
    "        \n",
    "        # Save the plot with high DPI\n",
    "        output_path = os.path.join(output_directory, f\"holaps_trend_group_{group_idx + 1}.png\")\n",
    "        plt.savefig(output_path, dpi=350, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"✓ Group {group_idx + 1} plot saved with {len(station_group)} stations\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing group {group_idx + 1}: {str(e)}\")\n",
    "        import traceback\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "print(\"All station groups processed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07f9a04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data from all HOLAPS stations...\n",
      "Collected yearly data for holaps_trend_tables_AT-Neu - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_AT-Neu - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_BE-Bra - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_BE-Bra - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_BE-Lon - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_BE-Lon - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_BE-Vie - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_BE-Vie - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_CH-Cha - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_CH-Cha - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_CH-Dav - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_CH-Dav - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_CH-Fru - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_CH-Fru - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_CZ-BK1 - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_CZ-BK1 - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_CZ-wet - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_CZ-wet - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_DE-Geb - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_DE-Geb - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_DE-Gri - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_DE-Gri - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_DE-Hai - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_DE-Hai - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_DE-HoH - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_DE-HoH - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_DE-Hzd - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_DE-Hzd - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_DE-Kli - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_DE-Kli - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_DE-Lnf - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_DE-Lnf - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_DE-Obe - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_DE-Obe - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_DE-RuR - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_DE-RuR - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_DE-RuS - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_DE-RuS - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_DE-Tha - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_DE-Tha - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_DK-Sor - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_DK-Sor - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_ES-Agu - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_ES-Agu - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_ES-LJu - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_ES-LJu - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_FR-Aur - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_FR-Aur - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_FR-Bil - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_FR-Bil - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_FR-Gri - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_FR-Gri - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_FR-Hes - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_FR-Hes - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_FR-Lam - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_FR-Lam - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_FR-LBr - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_FR-LBr - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_IT-BCi - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_IT-BCi - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_IT-Col - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_IT-Col - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_IT-Cp2 - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_IT-Cp2 - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_IT-Cpz - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_IT-Cpz - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_IT-Lav - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_IT-Lav - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_IT-MBo - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_IT-MBo - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_IT-Ren - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_IT-Ren - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_IT-Ro2 - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_IT-Ro2 - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_IT-SR2 - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_IT-SR2 - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_IT-SRo - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_IT-SRo - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_IT-Tor - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_IT-Tor - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_IT-TrF - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_IT-TrF - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_NL-Loo - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_NL-Loo - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_RU-Fyo - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_RU-Fyo - 13 parameters\n",
      "Collected yearly data for holaps_trend_tables_SE-Htm - 13 parameters\n",
      "Collected JJA data for holaps_trend_tables_SE-Htm - 13 parameters\n",
      "Data collection complete. Total records: 1144\n",
      "Creating comprehensive analysis plots...\n",
      "Comprehensive HOLAPS file saved: C:\\Deepak\\HOLAPS\\monthly\\station_data2\\yearly\\plots3\\comprehensive_holaps_analysis.xlsx\n",
      "Comprehensive bar plot created for Yearly season\n",
      "Comprehensive bar plot created for JJA (Summer) season\n",
      "Comprehensive bar plots created for both seasons!\n",
      "Venn diagrams created for Yearly season\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinthap\\AppData\\Local\\miniconda3\\envs\\new\\Lib\\site-packages\\matplotlib_venn\\layout\\venn3\\pairwise.py:107: UserWarning: Circle B has zero area.\n",
      "  warnings.warn(\"Circle B has zero area.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Venn diagrams created for Yearly season\n",
      "Venn diagrams created for JJA (Summer) season\n",
      "Venn diagrams created for JJA (Summer) season\n",
      "Venn diagrams created for both seasons!\n",
      "All comprehensive HOLAPS analysis completed!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from matplotlib_venn import venn2, venn3\n",
    "import seaborn as sns\n",
    "\n",
    "# Define parameters for HOLAPS\n",
    "parameters = [\n",
    "    'GHF', 'H', 'LE', 'Rn', 'Ta', 'Td', 'Ts', \n",
    "    'rain', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5'\n",
    "]\n",
    "\n",
    "# Directory containing Excel files\n",
    "input_directory = r'C:\\Deepak\\HOLAPS\\monthly\\station_data2\\yearly'\n",
    "output_directory = r'C:\\Deepak\\HOLAPS\\monthly\\station_data2\\yearly\\plots3'\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Global storage for significance data across all stations\n",
    "all_stations_selected_data = []\n",
    "\n",
    "# Get list of Excel files - separate yearly and JJA files\n",
    "yearly_files = [f for f in os.listdir(input_directory) if f.endswith('_yearly.xlsx')]\n",
    "jja_files = [f for f in os.listdir(input_directory) if f.endswith('_JJA.xlsx')]\n",
    "\n",
    "# Create a mapping between yearly and JJA files\n",
    "file_pairs = {}\n",
    "for y_file in yearly_files:\n",
    "    base_name = y_file.replace('_yearly.xlsx', '')\n",
    "    jja_file = base_name + '_JJA.xlsx'\n",
    "    if jja_file in jja_files:\n",
    "        file_pairs[base_name] = {'yearly': y_file, 'jja': jja_file}\n",
    "    else:\n",
    "        file_pairs[base_name] = {'yearly': y_file, 'jja': None}\n",
    "\n",
    "# Also include JJA files that don't have yearly counterparts\n",
    "for j_file in jja_files:\n",
    "    base_name = j_file.replace('_JJA.xlsx', '')\n",
    "    if base_name not in file_pairs:\n",
    "        file_pairs[base_name] = {'yearly': None, 'jja': j_file}\n",
    "\n",
    "def get_selected_period_data(station_name, p_values_df, slopes_df, parameters, season):\n",
    "    \"\"\"Get data for all periods (no weighting/selection needed for HOLAPS)\"\"\"\n",
    "    selected_data = []\n",
    "    \n",
    "    # For HOLAPS, we use only the \"Complete Period\" row (first row)\n",
    "    # Skip the \"Single Variable\" rows as they are redundant\n",
    "    complete_period_mask = p_values_df['Analysis'] == 'Complete Period'\n",
    "    \n",
    "    if complete_period_mask.any():\n",
    "        period_idx = complete_period_mask.idxmax()\n",
    "        \n",
    "        for param in parameters:\n",
    "            if param not in p_values_df.columns:\n",
    "                continue\n",
    "                \n",
    "            p_val = p_values_df[param].iloc[period_idx]\n",
    "            \n",
    "            # Handle slope data - check if parameter exists in slopes_df\n",
    "            if param in slopes_df.columns:\n",
    "                slope = slopes_df[param].iloc[period_idx]\n",
    "            else:\n",
    "                slope = np.nan\n",
    "            \n",
    "            # Skip if p-value or slope is NaN\n",
    "            if pd.isna(p_val) or pd.isna(slope):\n",
    "                continue\n",
    "            \n",
    "            # Determine significance level\n",
    "            if p_val < 0.1:\n",
    "                sig_level = 'high'\n",
    "            elif p_val < 0.2:\n",
    "                sig_level = 'medium'\n",
    "            else:\n",
    "                sig_level = 'insig'\n",
    "            \n",
    "            selected_data.append({\n",
    "                'station': station_name,\n",
    "                'parameter': param,\n",
    "                'season': season,\n",
    "                'significance': sig_level,\n",
    "                'p_value': p_val,\n",
    "                'slope': slope,\n",
    "                'period': p_values_df['Period'].iloc[period_idx] if 'Period' in p_values_df.columns else 'Complete Period'\n",
    "            })\n",
    "    \n",
    "    return selected_data\n",
    "\n",
    "\n",
    "def create_comprehensive_bar_plots_separate_seasons():\n",
    "    \"\"\"Create separate comprehensive bar plots for Yearly and JJA seasons\"\"\"\n",
    "    \n",
    "    # Filter data by season\n",
    "    yearly_data = [record for record in all_stations_selected_data if record['season'] == 'yearly']\n",
    "    jja_data = [record for record in all_stations_selected_data if record['season'] == 'JJA']\n",
    "    \n",
    "    # Pre-calculate maximum bar height for consistent Y-axis\n",
    "    max_bar_height = 0\n",
    "    \n",
    "    for season_data in [yearly_data, jja_data]:\n",
    "        if len(season_data) == 0:\n",
    "            continue\n",
    "            \n",
    "        param_summary = {}\n",
    "        for param in parameters:\n",
    "            param_summary[param] = {'high_sig': 0, 'medium_sig': 0, 'insig_sig': 0}\n",
    "        \n",
    "        for record in season_data:\n",
    "            param = record['parameter']\n",
    "            sig_level = record['significance']\n",
    "            \n",
    "            if sig_level == 'high':\n",
    "                key = 'high_sig'\n",
    "            elif sig_level == 'medium':\n",
    "                key = 'medium_sig'\n",
    "            else:\n",
    "                key = 'insig_sig'\n",
    "            \n",
    "            param_summary[param][key] += 1\n",
    "        \n",
    "        # Calculate total height for each parameter\n",
    "        for param in parameters:\n",
    "            if param in param_summary:\n",
    "                total = (param_summary[param]['high_sig'] + \n",
    "                        param_summary[param]['medium_sig'] + \n",
    "                        param_summary[param]['insig_sig'])\n",
    "                max_bar_height = max(max_bar_height, total)\n",
    "    \n",
    "    # Add some padding to the max height\n",
    "    y_max = max_bar_height * 1.15\n",
    "    \n",
    "    # Create separate plots for yearly and JJA\n",
    "    for season, season_data, season_name in [('yearly', yearly_data, 'Yearly'), ('JJA', jja_data, 'JJA (Summer)')]:\n",
    "        if len(season_data) == 0:\n",
    "            print(f\"No data available for {season_name}\")\n",
    "            continue\n",
    "            \n",
    "        # Create summary data for bar plot\n",
    "        param_summary = {}\n",
    "        for param in parameters:\n",
    "            param_summary[param] = {'high_sig': 0, 'medium_sig': 0, 'insig_sig': 0}\n",
    "        \n",
    "        for record in season_data:\n",
    "            param = record['parameter']\n",
    "            sig_level = record['significance']\n",
    "            \n",
    "            if sig_level == 'high':\n",
    "                key = 'high_sig'\n",
    "            elif sig_level == 'medium':\n",
    "                key = 'medium_sig'\n",
    "            else:\n",
    "                key = 'insig_sig'\n",
    "            \n",
    "            param_summary[param][key] += 1\n",
    "        \n",
    "        # Prepare data for stacked bar plot - REVERSED ORDER\n",
    "        params = list(param_summary.keys())\n",
    "        insig = [param_summary[param]['insig_sig'] for param in params]\n",
    "        medium_sig = [param_summary[param]['medium_sig'] for param in params]\n",
    "        high_sig = [param_summary[param]['high_sig'] for param in params]\n",
    "        \n",
    "        # Create the plot\n",
    "        fig, ax = plt.subplots(figsize=(16, 10))\n",
    "        \n",
    "        bar_width = 0.8\n",
    "        x_pos = np.arange(len(params))\n",
    "        \n",
    "        # Plot in reversed order: Not significant at bottom, then medium, then high\n",
    "        bars1 = ax.bar(x_pos, insig, bar_width, label='Not Significant (p ≥ 0.2)', \n",
    "                       color='#d62728', edgecolor='black', linewidth=1)\n",
    "        bars2 = ax.bar(x_pos, medium_sig, bar_width, bottom=insig, \n",
    "                       label='Moderately Significant (0.1 ≤ p < 0.2)', \n",
    "                       color='#ff7f0e', edgecolor='black', linewidth=1)\n",
    "        bars3 = ax.bar(x_pos, high_sig, bar_width, bottom=np.array(insig) + np.array(medium_sig),\n",
    "                       label='Highly Significant (p < 0.1)', \n",
    "                       color='#2ca02c', edgecolor='black', linewidth=1)\n",
    "        \n",
    "        # Add value labels on bars - FIXED POSITIONING\n",
    "        for i, (n, m, h) in enumerate(zip(insig, medium_sig, high_sig)):\n",
    "            total = n + m + h\n",
    "            if total > 0:\n",
    "                # Total count at top of bar - position relative to bar height\n",
    "                y_pos_total = total + (y_max * 0.02)  # Small offset above bar\n",
    "                ax.text(i, y_pos_total, f'{total}', ha='center', va='bottom', \n",
    "                       fontweight='bold', fontsize=10, color='black')\n",
    "                \n",
    "                # Individual counts inside segments - only if segment is large enough\n",
    "                segment_threshold = y_max * 0.08  # Only label segments taller than 8% of max height\n",
    "                \n",
    "                if n >= segment_threshold:  # Not significant\n",
    "                    ax.text(i, n/2, f'{n}', ha='center', va='center', \n",
    "                           fontweight='bold', fontsize=9, color='white')\n",
    "                \n",
    "                if m >= segment_threshold:  # Moderately significant\n",
    "                    ax.text(i, n + m/2, f'{m}', ha='center', va='center', \n",
    "                           fontweight='bold', fontsize=9, color='white')\n",
    "                \n",
    "                if h >= segment_threshold:  # Highly significant\n",
    "                    ax.text(i, n + m + h/2, f'{h}', ha='center', va='center', \n",
    "                           fontweight='bold', fontsize=9, color='white')\n",
    "        \n",
    "        # Set consistent Y-axis limits\n",
    "        ax.set_ylim(0, y_max)\n",
    "        \n",
    "        # Customize plot\n",
    "        ax.set_xlabel('Parameters', fontsize=14, fontweight='bold')\n",
    "        ax.set_ylabel('Number of Stations', fontsize=14, fontweight='bold')\n",
    "        ax.set_title(f'Significance Analysis - {season_name} Season (HOLAPS)', \n",
    "                     fontsize=16, fontweight='bold', pad=20)\n",
    "        ax.set_xticks(x_pos)\n",
    "        ax.set_xticklabels(params, rotation=45, ha='right', fontsize=12)\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=12)\n",
    "        ax.grid(True, axis='y', alpha=0.3)\n",
    "        \n",
    "        # Calculate statistics for annotation\n",
    "        total_stations = len(set([record['station'] for record in season_data]))\n",
    "        total_high = sum(high_sig)\n",
    "        total_medium = sum(medium_sig)\n",
    "        total_insig = sum(insig)\n",
    "        total_all = total_high + total_medium + total_insig\n",
    "        sig_percentage = (total_high + total_medium) / total_all * 100 if total_all > 0 else 0\n",
    "        \n",
    "        # Add statistics outside the plot area\n",
    "        stats_text = (\n",
    "            f'Total Stations: {total_stations}\\n'\n",
    "            f'Total Parameters: {total_all}\\n'\n",
    "            f'Highly Significant: {total_high} ({total_high/total_all*100:.1f}%)\\n'\n",
    "            f'Moderately Significant: {total_medium} ({total_medium/total_all*100:.1f}%)\\n'\n",
    "            f'Not Significant: {total_insig} ({total_insig/total_all*100:.1f}%)\\n'\n",
    "            f'Overall Significant: {total_high + total_medium}/{total_all} ({sig_percentage:.1f}%)'\n",
    "        )\n",
    "        \n",
    "        # Place statistics on the right side outside the plot\n",
    "        ax.text(1.02, 0.5, stats_text, transform=ax.transAxes, fontsize=11, \n",
    "                fontweight='bold', verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8),\n",
    "                linespacing=1.5)\n",
    "        \n",
    "        # Adjust plot margins to accommodate the statistics text\n",
    "        plt.subplots_adjust(right=0.75)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_directory, f'comprehensive_significance_{season}.png'), \n",
    "                    dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"Comprehensive bar plot created for {season_name} season\")\n",
    "\n",
    "def create_venn_diagrams_separate_seasons():\n",
    "    \"\"\"Create separate Venn diagrams for Yearly and JJA seasons with requested combinations\"\"\"\n",
    "    \n",
    "    if len(all_stations_selected_data) == 0:\n",
    "        print(\"No selected period data found for Venn diagrams\")\n",
    "        return\n",
    "    \n",
    "    # Create separate Venn diagrams for yearly and JJA\n",
    "    for season, season_name in [('yearly', 'Yearly'), ('JJA', 'JJA (Summer)')]:\n",
    "        # Filter data by season and significance\n",
    "        season_data = [record for record in all_stations_selected_data if record['season'] == season]\n",
    "        sig_season_data = [record for record in season_data if record['p_value'] < 0.2]\n",
    "        \n",
    "        if len(sig_season_data) == 0:\n",
    "            print(f\"No significant records found for {season_name} Venn diagrams\")\n",
    "            continue\n",
    "        \n",
    "        # Create DataFrame for easier manipulation\n",
    "        sig_df = pd.DataFrame(sig_season_data)\n",
    "        \n",
    "        # Group by station and parameter to get stations with at least one significant parameter\n",
    "        station_params = sig_df.groupby(['station', 'parameter']).size().reset_index()\n",
    "        \n",
    "        # Create sets for different parameter groups\n",
    "        le_stations = set(station_params[station_params['parameter'] == 'LE']['station'])\n",
    "        h_stations = set(station_params[station_params['parameter'] == 'H']['station'])\n",
    "        rn_stations = set(station_params[station_params['parameter'] == 'Rn']['station'])\n",
    "        sm1_stations = set(station_params[station_params['parameter'] == 'sm1']['station'])\n",
    "        rain_stations = set(station_params[station_params['parameter'] == 'rain']['station'])\n",
    "        ta_stations = set(station_params[station_params['parameter'] == 'Ta']['station'])\n",
    "        ts_stations = set(station_params[station_params['parameter'] == 'Ts']['station'])\n",
    "        ghf_stations = set(station_params[station_params['parameter'] == 'GHF']['station'])\n",
    "        td_stations = set(station_params[station_params['parameter'] == 'Td']['station'])\n",
    "        \n",
    "        # For ALL combo - stations that have significant trends in ALL 13 parameters\n",
    "        all_params_stations = set()\n",
    "        all_param_sets = [le_stations, h_stations, rn_stations, \n",
    "                         ta_stations, td_stations, ts_stations,\n",
    "                         rain_stations, sm1_stations, ghf_stations]\n",
    "        \n",
    "       \n",
    "        \n",
    "        # Create Venn diagrams - 2x2 grid for the 5 combinations\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 14))\n",
    "        \n",
    "        # Combo 1: LE vs H vs Rn\n",
    "        if le_stations or h_stations or rn_stations:\n",
    "            venn3([le_stations, h_stations, rn_stations],\n",
    "                  ['LE', 'H', 'Rn'], ax=ax1)\n",
    "            ax1.set_title(f'1. LE vs H vs Rn\\n({season_name})', fontsize=14, fontweight='bold')\n",
    "        else:\n",
    "            ax1.text(0.5, 0.5, 'No significant data', ha='center', va='center', transform=ax1.transAxes, fontsize=12)\n",
    "            ax1.set_title(f'1. LE vs H vs Rn\\n({season_name})', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Combo 2: LE vs sm1 vs rain\n",
    "        if le_stations or sm1_stations or rain_stations:\n",
    "            venn3([le_stations, sm1_stations, rain_stations],\n",
    "                  ['LE', 'sm1', 'rain'], ax=ax2)\n",
    "            ax2.set_title(f'2. LE vs sm1 vs rain\\n({season_name})', fontsize=14, fontweight='bold')\n",
    "        else:\n",
    "            ax2.text(0.5, 0.5, 'No significant data', ha='center', va='center', transform=ax2.transAxes, fontsize=12)\n",
    "            ax2.set_title(f'2. LE vs sm1 vs rain\\n({season_name})', fontsize=14, fontweight='bold')\n",
    "        \n",
    "       \n",
    "      \n",
    "        # Combo 3: H vs Ta vs Ts\n",
    "        if h_stations or ta_stations or ts_stations:\n",
    "            venn3([h_stations, ta_stations, ts_stations],\n",
    "                  ['H', 'Ta', 'Ts'], ax=ax3)\n",
    "            ax3.set_title(f'3. H vs Ta vs Ts\\n({season_name})', fontsize=14, fontweight='bold')\n",
    "        else:\n",
    "            ax3.text(0.5, 0.5, 'No significant data', ha='center', va='center', transform=ax3.transAxes, fontsize=12)\n",
    "            ax3.set_title(f'3. H vs Ta vs Ts\\n({season_name})', fontsize=14, fontweight='bold')\n",
    "\n",
    "        # Combo 4: H vs GHF vs sm1\n",
    "        if h_stations or ghf_stations or sm1_stations:\n",
    "            venn3([h_stations, ghf_stations, sm1_stations],\n",
    "                  ['H', 'GHF', 'sm1'], ax=ax4)\n",
    "            ax4.set_title(f'4. H vs GHF vs sm1\\n({season_name})', fontsize=14, fontweight='bold')\n",
    "        else:\n",
    "            ax4.text(0.5, 0.5, 'No significant data', ha='center', va='center', transform=ax4.transAxes, fontsize=12)\n",
    "            ax4.set_title(f'4. H vs GHF vs sm1\\n({season_name})', fontsize=14, fontweight='bold')\n",
    "        \n",
    "       \n",
    "       \n",
    "        print(f\"Venn diagrams created for {season_name} season\")    \n",
    "        \n",
    "        plt.suptitle(f'Venn Diagrams - {season_name} Season (HOLAPS)\\n(p < 0.2)', \n",
    "                     fontsize=16, fontweight='bold', y=0.95)\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.savefig(os.path.join(output_directory, f'venn_diagrams_{season}.png'), \n",
    "                    dpi=300, bbox_inches='tight')\n",
    "      \n",
    "     \n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"Venn diagrams created for {season_name} season\")\n",
    "\n",
    "# [Keep the save_comprehensive_selection_file() function as before, just rename the output file]\n",
    "def save_comprehensive_selection_file():\n",
    "    \"\"\"Save comprehensive data to Excel file with separate sheets for seasons\"\"\"\n",
    "    if len(all_stations_selected_data) == 0:\n",
    "        print(\"No data to save\")\n",
    "        return\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    comp_df = pd.DataFrame(all_stations_selected_data)\n",
    "    \n",
    "    # Save to Excel\n",
    "    output_file = os.path.join(output_directory, 'comprehensive_holaps_analysis.xlsx')\n",
    "    \n",
    "    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "        # Save main data\n",
    "        comp_df.to_excel(writer, sheet_name='All_Data', index=False)\n",
    "        \n",
    "        # Create separate sheets for yearly and JJA\n",
    "        for season, season_name in [('yearly', 'Yearly'), ('JJA', 'JJA_Summer')]:\n",
    "            season_data = comp_df[comp_df['season'] == season]\n",
    "            if len(season_data) > 0:\n",
    "                season_data.to_excel(writer, sheet_name=f'{season_name}_Data', index=False)\n",
    "        \n",
    "        # Create summary sheet\n",
    "        summary_data = []\n",
    "        stations = comp_df['station'].unique()\n",
    "        \n",
    "        for station in stations:\n",
    "            station_data = comp_df[comp_df['station'] == station]\n",
    "            # Separate by season\n",
    "            yearly_data = station_data[station_data['season'] == 'yearly']\n",
    "            jja_data = station_data[station_data['season'] == 'JJA']\n",
    "            \n",
    "            # Yearly summary\n",
    "            if len(yearly_data) > 0:\n",
    "                high_sig_yearly = len(yearly_data[yearly_data['significance'] == 'high'])\n",
    "                medium_sig_yearly = len(yearly_data[yearly_data['significance'] == 'medium'])\n",
    "                insig_yearly = len(yearly_data[yearly_data['significance'] == 'insig'])\n",
    "                total_params_yearly = len(yearly_data)\n",
    "            else:\n",
    "                high_sig_yearly = medium_sig_yearly = insig_yearly = total_params_yearly = 0\n",
    "            \n",
    "            # JJA summary\n",
    "            if len(jja_data) > 0:\n",
    "                high_sig_jja = len(jja_data[jja_data['significance'] == 'high'])\n",
    "                medium_sig_jja = len(jja_data[jja_data['significance'] == 'medium'])\n",
    "                insig_jja = len(jja_data[jja_data['significance'] == 'insig'])\n",
    "                total_params_jja = len(jja_data)\n",
    "            else:\n",
    "                high_sig_jja = medium_sig_jja = insig_jja = total_params_jja = 0\n",
    "            \n",
    "            summary_data.append({\n",
    "                'Station': station,\n",
    "                'Yearly_Total_Params': total_params_yearly,\n",
    "                'Yearly_High_Sig': high_sig_yearly,\n",
    "                'Yearly_Medium_Sig': medium_sig_yearly,\n",
    "                'Yearly_Not_Sig': insig_yearly,\n",
    "                'JJA_Total_Params': total_params_jja,\n",
    "                'JJA_High_Sig': high_sig_jja,\n",
    "                'JJA_Medium_Sig': medium_sig_jja,\n",
    "                'JJA_Not_Sig': insig_jja\n",
    "            })\n",
    "        \n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        summary_df.to_excel(writer, sheet_name='Station_Summary', index=False)\n",
    "        \n",
    "        # Create parameter summary sheets for each season\n",
    "        for season, season_name in [('yearly', 'Yearly'), ('JJA', 'JJA')]:\n",
    "            season_data = comp_df[comp_df['season'] == season]\n",
    "            if len(season_data) > 0:\n",
    "                param_summary_data = []\n",
    "                for param in parameters:\n",
    "                    param_data = season_data[season_data['parameter'] == param]\n",
    "                    total_stations = len(param_data)\n",
    "                    high_sig = len(param_data[param_data['significance'] == 'high'])\n",
    "                    medium_sig = len(param_data[param_data['significance'] == 'medium'])\n",
    "                    insig = len(param_data[param_data['significance'] == 'insig'])\n",
    "                    \n",
    "                    param_summary_data.append({\n",
    "                        'Parameter': param,\n",
    "                        'Total_Stations': total_stations,\n",
    "                        'Highly_Significant': high_sig,\n",
    "                        'Moderately_Significant': medium_sig,\n",
    "                        'Not_Significant': insig,\n",
    "                        'Significant_Count': high_sig + medium_sig,\n",
    "                        'Significant_Percentage': ((high_sig + medium_sig) / total_stations * 100) if total_stations > 0 else 0\n",
    "                    })\n",
    "                \n",
    "                param_summary_df = pd.DataFrame(param_summary_data)\n",
    "                param_summary_df.to_excel(writer, sheet_name=f'Parameter_Summary_{season_name}', index=False)\n",
    "    \n",
    "    print(f\"Comprehensive HOLAPS file saved: {output_file}\")\n",
    "\n",
    "# Main processing - collect data from all stations\n",
    "print(\"Collecting data from all HOLAPS stations...\")\n",
    "\n",
    "for base_name, files in file_pairs.items():\n",
    "    try:\n",
    "        # Process yearly data\n",
    "        if files['yearly']:\n",
    "            yearly_file_path = os.path.join(input_directory, files['yearly'])\n",
    "            try:\n",
    "                p_values_df_yearly = pd.read_excel(yearly_file_path, sheet_name='P-values')\n",
    "                slopes_df_yearly = pd.read_excel(yearly_file_path, sheet_name='Slopes')\n",
    "                \n",
    "                # Clean the data - only use \"Complete Period\" row\n",
    "                p_values_df_yearly = p_values_df_yearly.dropna(how='all')\n",
    "                slopes_df_yearly = slopes_df_yearly.dropna(how='all')\n",
    "                \n",
    "                # Store only the \"Complete Period\" data for HOLAPS\n",
    "                selected_data = get_selected_period_data(\n",
    "                    base_name, p_values_df_yearly, slopes_df_yearly, \n",
    "                    parameters, 'yearly')\n",
    "                all_stations_selected_data.extend(selected_data)\n",
    "                print(f\"Collected yearly data for {base_name} - {len(selected_data)} parameters\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error loading yearly data for {base_name}: {str(e)}\")\n",
    "        \n",
    "        # Process JJA data\n",
    "        if files['jja']:\n",
    "            jja_file_path = os.path.join(input_directory, files['jja'])\n",
    "            try:\n",
    "                p_values_df_jja = pd.read_excel(jja_file_path, sheet_name='P-values')\n",
    "                slopes_df_jja = pd.read_excel(jja_file_path, sheet_name='Slopes')\n",
    "                \n",
    "                # Clean the data - only use \"Complete Period\" row\n",
    "                p_values_df_jja = p_values_df_jja.dropna(how='all')\n",
    "                slopes_df_jja = slopes_df_jja.dropna(how='all')\n",
    "                \n",
    "                # Store only the \"Complete Period\" data for HOLAPS\n",
    "                selected_data = get_selected_period_data(\n",
    "                    base_name, p_values_df_jja, slopes_df_jja, \n",
    "                    parameters, 'JJA')\n",
    "                all_stations_selected_data.extend(selected_data)\n",
    "                print(f\"Collected JJA data for {base_name} - {len(selected_data)} parameters\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error loading JJA data for {base_name}: {str(e)}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {base_name}: {str(e)}\")\n",
    "\n",
    "print(f\"Data collection complete. Total records: {len(all_stations_selected_data)}\")\n",
    "\n",
    "\n",
    "\n",
    "# Create comprehensive plots and save file\n",
    "print(\"Creating comprehensive analysis plots...\")\n",
    "\n",
    "# Save comprehensive selection file\n",
    "save_comprehensive_selection_file()\n",
    "\n",
    "# Create comprehensive bar plots (separate for yearly and JJA)\n",
    "create_comprehensive_bar_plots_separate_seasons()\n",
    "print(\"Comprehensive bar plots created for both seasons!\")\n",
    "\n",
    "# Create Venn diagrams (separate for yearly and JJA)\n",
    "create_venn_diagrams_separate_seasons()\n",
    "print(\"Venn diagrams created for both seasons!\")\n",
    "\n",
    "print(\"All comprehensive HOLAPS analysis completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
